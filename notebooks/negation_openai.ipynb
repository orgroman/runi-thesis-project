{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "patentmatch_dataset_root = Path(r'C:\\workspace_or_private\\repos\\runi-thesis-project\\hidrive')\n",
    "test_data_path = patentmatch_dataset_root / 'patentmatch_test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsv_file = test_data_path / 'patentmatch_test.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(tsv_file, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1251940"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['text_b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonl_var = df.head().to_json(orient='records', lines=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the reduced df to csv\n",
    "reduced_csv_file = test_data_path / 'patentmatch_test_no_claims.csv'\n",
    "df.to_csv(reduced_csv_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          column  token_sum  token_mean   token_std  token_median   char_sum  \\\n",
      "0           text   44852194  120.553562  103.813916          91.0  235169004   \n",
      "1         text_b   43253910  116.257701   98.774692          95.0  215112539   \n",
      "2  text + text_b   88106104  118.405631  101.348399          93.0  450281543   \n",
      "\n",
      "    char_mean    char_std  char_median  \n",
      "0  632.086386  525.870946        486.0  \n",
      "1  578.178693  469.818857        475.0  \n",
      "2  605.132539  499.361107        479.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tiktoken\n",
    "import statistics\n",
    "\n",
    "# Example: Load your data frame (assumed already loaded in df)\n",
    "# df = pd.read_csv(\"some_file.csv\")\n",
    "\n",
    "# Create an encoding object (adjust as needed for your model)\n",
    "enc = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "# --- 1) Compute token counts and char counts for each column ---\n",
    "\n",
    "# 'text'\n",
    "token_counts_text = [len(enc.encode(str(x))) for x in df['text']]\n",
    "char_counts_text = df['text'].astype(str).apply(len)\n",
    "\n",
    "# 'text_b'\n",
    "token_counts_text_b = [len(enc.encode(str(x))) for x in df['text_b']]\n",
    "char_counts_text_b = df['text_b'].astype(str).apply(len)\n",
    "\n",
    "# Combined: text + text_b\n",
    "token_counts_all = token_counts_text + token_counts_text_b\n",
    "char_counts_all = list(char_counts_text) + list(char_counts_text_b)\n",
    "\n",
    "# --- 2) Helper function to compute statistics ---\n",
    "\n",
    "def compute_stats(values, stat_label=\"\"):\n",
    "    \"\"\"\n",
    "    values: list or Series of numeric values\n",
    "    Returns a dict with sum, mean, std, and median\n",
    "    Note: using population std (pstdev).\n",
    "          If you want sample std, use statistics.stdev().\n",
    "    \"\"\"\n",
    "    return {\n",
    "        f\"{stat_label}sum\": sum(values),\n",
    "        f\"{stat_label}mean\": statistics.mean(values),\n",
    "        f\"{stat_label}std\": statistics.pstdev(values),\n",
    "        f\"{stat_label}median\": statistics.median(values)\n",
    "    }\n",
    "\n",
    "# --- 3) Build up a list of dicts for our final DataFrame ---\n",
    "\n",
    "stats_data = []\n",
    "\n",
    "# A) text column\n",
    "text_token_stats = compute_stats(token_counts_text, \"token_\")\n",
    "text_char_stats = compute_stats(char_counts_text, \"char_\")\n",
    "stats_data.append({\n",
    "    \"column\": \"text\",\n",
    "    **text_token_stats,\n",
    "    **text_char_stats\n",
    "})\n",
    "\n",
    "# B) text_b column\n",
    "text_b_token_stats = compute_stats(token_counts_text_b, \"token_\")\n",
    "text_b_char_stats = compute_stats(char_counts_text_b, \"char_\")\n",
    "stats_data.append({\n",
    "    \"column\": \"text_b\",\n",
    "    **text_b_token_stats,\n",
    "    **text_b_char_stats\n",
    "})\n",
    "\n",
    "# C) text + text_b\n",
    "all_token_stats = compute_stats(token_counts_all, \"token_\")\n",
    "all_char_stats = compute_stats(char_counts_all, \"char_\")\n",
    "stats_data.append({\n",
    "    \"column\": \"text + text_b\",\n",
    "    **all_token_stats,\n",
    "    **all_char_stats\n",
    "})\n",
    "\n",
    "# --- 4) Create a new DataFrame with our statistics ---\n",
    "stats_df = pd.DataFrame(stats_data)\n",
    "\n",
    "# --- 5) Print or otherwise use stats_df ---\n",
    "print(stats_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW_VAL\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getenv('MY_VAR','NA'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
