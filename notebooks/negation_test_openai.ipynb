{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Azure Key Vault and OpenAI Credentials\n",
    "\n",
    "Securely retrieve OpenAI API key from Azure Key Vault for authentication.\n",
    "This ensures sensitive credentials are not hardcoded in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:azure.identity._credentials.environment:No environment configuration found.\n",
      "INFO:azure.identity._credentials.managed_identity:ManagedIdentityCredential will use IMDS\n",
      "INFO:azure.core.pipeline.policies.http_logging_policy:Request URL: 'http://169.254.169.254/metadata/identity/oauth2/token?api-version=REDACTED&resource=REDACTED'\n",
      "Request method: 'GET'\n",
      "Request headers:\n",
      "    'User-Agent': 'azsdk-python-identity/1.20.0 Python/3.11.8 (Windows-10-10.0.22631-SP0)'\n",
      "No body was attached to the request\n",
      "INFO:azure.identity._credentials.chained:DefaultAzureCredential acquired a token from AzureCliCredential\n",
      "INFO:azure.core.pipeline.policies.http_logging_policy:Request URL: 'https://kvrunithesis.vault.azure.net/secrets/alon-thesis-openai-key/?api-version=REDACTED'\n",
      "Request method: 'GET'\n",
      "Request headers:\n",
      "    'Accept': 'application/json'\n",
      "    'x-ms-client-request-id': '385a5536-f1a5-11ef-b41c-a0806955d9fc'\n",
      "    'User-Agent': 'azsdk-python-keyvault-secrets/4.9.0 Python/3.11.8 (Windows-10-10.0.22631-SP0)'\n",
      "    'Authorization': 'REDACTED'\n",
      "No body was attached to the request\n",
      "INFO:azure.core.pipeline.policies.http_logging_policy:Response status: 200\n",
      "Response headers:\n",
      "    'Cache-Control': 'no-cache'\n",
      "    'Pragma': 'no-cache'\n",
      "    'Content-Type': 'application/json; charset=utf-8'\n",
      "    'Expires': '-1'\n",
      "    'x-ms-keyvault-region': 'centralus'\n",
      "    'x-ms-client-request-id': '385a5536-f1a5-11ef-b41c-a0806955d9fc'\n",
      "    'x-ms-request-id': '1c787ac8-2b68-4b9a-8a0e-aad709b233b7'\n",
      "    'x-ms-keyvault-service-version': '1.9.2103.1'\n",
      "    'x-ms-keyvault-network-info': 'conn_type=Ipv4;addr=62.56.149.232;act_addr_fam=InterNetwork;'\n",
      "    'x-ms-keyvault-rbac-assignment-id': 'REDACTED'\n",
      "    'X-Content-Type-Options': 'REDACTED'\n",
      "    'Strict-Transport-Security': 'REDACTED'\n",
      "    'Date': 'Sun, 23 Feb 2025 05:15:44 GMT'\n",
      "    'Content-Length': '491'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully retrieved OpenAI API key from Azure Key Vault\n"
     ]
    }
   ],
   "source": [
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.keyvault.secrets import SecretClient\n",
    "import os\n",
    "\n",
    "def get_openai_key():\n",
    "    \"\"\"Retrieve OpenAI API key from Azure Key Vault\"\"\"\n",
    "    try:\n",
    "        # Initialize the Azure credentials\n",
    "        credential = DefaultAzureCredential()\n",
    "        \n",
    "        # Create a secret client\n",
    "        vault_url = f\"https://kvrunithesis.vault.azure.net/\"\n",
    "        secret_client = SecretClient(vault_url=vault_url, credential=credential)\n",
    "        \n",
    "        # Get the secret\n",
    "        secret = secret_client.get_secret(\"alon-thesis-openai-key\")\n",
    "        \n",
    "        # Set as environment variable\n",
    "        os.environ[\"OPENAI_API_KEY\"] = secret.value\n",
    "        os.environ[\"THESIS_ALON_OPENAI_API_KEY\"] = secret.value\n",
    "        \n",
    "        print(\"Successfully retrieved OpenAI API key from Azure Key Vault\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving secret from Key Vault: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# Retrieve and set the OpenAI API key\n",
    "get_openai_key()\n",
    "\n",
    "# Now you can initialize the OpenAI client which will automatically use the environment variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the test data\n",
    "csv_file = r'C:\\Users\\orgrd\\workspace\\data\\patentmatch_test\\patentmatch_test_no_claims.csv'\n",
    "df = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>claim_id</th>\n",
       "      <th>patent_application_id</th>\n",
       "      <th>cited_document_id</th>\n",
       "      <th>text</th>\n",
       "      <th>text_b</th>\n",
       "      <th>label</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5113165</td>\n",
       "      <td>5113165</td>\n",
       "      <td>111187_0</td>\n",
       "      <td>EP3157302A1</td>\n",
       "      <td>EP2903333</td>\n",
       "      <td>A network of handling a paging procedure in a ...</td>\n",
       "      <td>FIG.16 is a diagram illustrating an example of...</td>\n",
       "      <td>0</td>\n",
       "      <td>20170419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5658863</td>\n",
       "      <td>5658863</td>\n",
       "      <td>209068_1</td>\n",
       "      <td>EP3202314A1</td>\n",
       "      <td>EP2229880</td>\n",
       "      <td>A sensor information processing program for ca...</td>\n",
       "      <td>In a first step the fundamental movement frequ...</td>\n",
       "      <td>1</td>\n",
       "      <td>20170809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5584990</td>\n",
       "      <td>5584990</td>\n",
       "      <td>171472_0</td>\n",
       "      <td>EP3196007A1</td>\n",
       "      <td>EP2939828</td>\n",
       "      <td>A moulded trim part for a vehicle according to...</td>\n",
       "      <td>It was found that the thermoplastic polyuretha...</td>\n",
       "      <td>0</td>\n",
       "      <td>20170726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5137320</td>\n",
       "      <td>5137320</td>\n",
       "      <td>87572_0</td>\n",
       "      <td>EP3160147A1</td>\n",
       "      <td>EP1670252</td>\n",
       "      <td>A method for fast channel change characterized...</td>\n",
       "      <td>As to the issue of delivery modes the strategy...</td>\n",
       "      <td>0</td>\n",
       "      <td>20170426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5800528</td>\n",
       "      <td>5800528</td>\n",
       "      <td>204115_0</td>\n",
       "      <td>EP3217403A1</td>\n",
       "      <td>EP1855216</td>\n",
       "      <td>An audio asset information storage system comp...</td>\n",
       "      <td>Further it is assumed in the above circumstanc...</td>\n",
       "      <td>0</td>\n",
       "      <td>20170913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    index  claim_id patent_application_id cited_document_id  \\\n",
       "0     5113165  5113165  111187_0           EP3157302A1         EP2903333   \n",
       "1     5658863  5658863  209068_1           EP3202314A1         EP2229880   \n",
       "2     5584990  5584990  171472_0           EP3196007A1         EP2939828   \n",
       "3     5137320  5137320   87572_0           EP3160147A1         EP1670252   \n",
       "4     5800528  5800528  204115_0           EP3217403A1         EP1855216   \n",
       "\n",
       "                                                text  \\\n",
       "0  A network of handling a paging procedure in a ...   \n",
       "1  A sensor information processing program for ca...   \n",
       "2  A moulded trim part for a vehicle according to...   \n",
       "3  A method for fast channel change characterized...   \n",
       "4  An audio asset information storage system comp...   \n",
       "\n",
       "                                              text_b  label      date  \n",
       "0  FIG.16 is a diagram illustrating an example of...      0  20170419  \n",
       "1  In a first step the fundamental movement frequ...      1  20170809  \n",
       "2  It was found that the thermoplastic polyuretha...      0  20170726  \n",
       "3  As to the issue of delivery modes the strategy...      0  20170426  \n",
       "4  Further it is assumed in the above circumstanc...      0  20170913  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare JSONL Files for OpenAI Processing\n",
    "\n",
    "This section prepares the data for batch processing with OpenAI's API. Here's what we're doing:\n",
    "\n",
    "1. **Setup**: Import required libraries and configure logging\n",
    "2. **Data Model**: Define a Pydantic model `NegationResponse` to validate OpenAI's responses\n",
    "3. **Batch Processing**: \n",
    "   - Split data into batches of 1000 rows each\n",
    "   - Create JSONL files with proper OpenAI API format\n",
    "   - Each line contains:\n",
    "     - Custom ID for tracking\n",
    "     - API endpoint\n",
    "     - Request body with messages and response format\n",
    "4. **Output**: Save batches as separate JSONL files in `output_jsonl` directory\n",
    "\n",
    "The JSONL format is required for OpenAI's batch processing endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Processing batch 1/373\n",
      "INFO:__main__:Stored batch 0 in MongoDB with key 'pmtest:jsonls:batch_0'\n",
      "INFO:__main__:Processing batch 2/373\n",
      "INFO:__main__:Stored batch 1 in MongoDB with key 'pmtest:jsonls:batch_1'\n",
      "INFO:__main__:Processing batch 3/373\n",
      "INFO:__main__:Stored batch 2 in MongoDB with key 'pmtest:jsonls:batch_2'\n",
      "INFO:__main__:Processing batch 4/373\n",
      "INFO:__main__:Stored batch 3 in MongoDB with key 'pmtest:jsonls:batch_3'\n",
      "INFO:__main__:Processing batch 5/373\n",
      "INFO:__main__:Stored batch 4 in MongoDB with key 'pmtest:jsonls:batch_4'\n",
      "INFO:__main__:Processing batch 6/373\n",
      "INFO:__main__:Stored batch 5 in MongoDB with key 'pmtest:jsonls:batch_5'\n",
      "INFO:__main__:Processing batch 7/373\n",
      "INFO:__main__:Stored batch 6 in MongoDB with key 'pmtest:jsonls:batch_6'\n",
      "INFO:__main__:Processing batch 8/373\n",
      "INFO:__main__:Stored batch 7 in MongoDB with key 'pmtest:jsonls:batch_7'\n",
      "INFO:__main__:Processing batch 9/373\n",
      "INFO:__main__:Stored batch 8 in MongoDB with key 'pmtest:jsonls:batch_8'\n",
      "INFO:__main__:Processing batch 10/373\n",
      "INFO:__main__:Stored batch 9 in MongoDB with key 'pmtest:jsonls:batch_9'\n",
      "INFO:__main__:Processing batch 11/373\n",
      "INFO:__main__:Stored batch 10 in MongoDB with key 'pmtest:jsonls:batch_10'\n",
      "INFO:__main__:Processing batch 12/373\n",
      "INFO:__main__:Stored batch 11 in MongoDB with key 'pmtest:jsonls:batch_11'\n",
      "INFO:__main__:Processing batch 13/373\n",
      "INFO:__main__:Stored batch 12 in MongoDB with key 'pmtest:jsonls:batch_12'\n",
      "INFO:__main__:Processing batch 14/373\n",
      "INFO:__main__:Stored batch 13 in MongoDB with key 'pmtest:jsonls:batch_13'\n",
      "INFO:__main__:Processing batch 15/373\n",
      "INFO:__main__:Stored batch 14 in MongoDB with key 'pmtest:jsonls:batch_14'\n",
      "INFO:__main__:Processing batch 16/373\n",
      "INFO:__main__:Stored batch 15 in MongoDB with key 'pmtest:jsonls:batch_15'\n",
      "INFO:__main__:Processing batch 17/373\n",
      "INFO:__main__:Stored batch 16 in MongoDB with key 'pmtest:jsonls:batch_16'\n",
      "INFO:__main__:Processing batch 18/373\n",
      "INFO:__main__:Stored batch 17 in MongoDB with key 'pmtest:jsonls:batch_17'\n",
      "INFO:__main__:Processing batch 19/373\n",
      "INFO:__main__:Stored batch 18 in MongoDB with key 'pmtest:jsonls:batch_18'\n",
      "INFO:__main__:Processing batch 20/373\n",
      "INFO:__main__:Stored batch 19 in MongoDB with key 'pmtest:jsonls:batch_19'\n",
      "INFO:__main__:Processing batch 21/373\n",
      "INFO:__main__:Stored batch 20 in MongoDB with key 'pmtest:jsonls:batch_20'\n",
      "INFO:__main__:Processing batch 22/373\n",
      "INFO:__main__:Stored batch 21 in MongoDB with key 'pmtest:jsonls:batch_21'\n",
      "INFO:__main__:Processing batch 23/373\n",
      "INFO:__main__:Stored batch 22 in MongoDB with key 'pmtest:jsonls:batch_22'\n",
      "INFO:__main__:Processing batch 24/373\n",
      "INFO:__main__:Stored batch 23 in MongoDB with key 'pmtest:jsonls:batch_23'\n",
      "INFO:__main__:Processing batch 25/373\n",
      "INFO:__main__:Stored batch 24 in MongoDB with key 'pmtest:jsonls:batch_24'\n",
      "INFO:__main__:Processing batch 26/373\n",
      "INFO:__main__:Stored batch 25 in MongoDB with key 'pmtest:jsonls:batch_25'\n",
      "INFO:__main__:Processing batch 27/373\n",
      "INFO:__main__:Stored batch 26 in MongoDB with key 'pmtest:jsonls:batch_26'\n",
      "INFO:__main__:Processing batch 28/373\n",
      "INFO:__main__:Stored batch 27 in MongoDB with key 'pmtest:jsonls:batch_27'\n",
      "INFO:__main__:Processing batch 29/373\n",
      "INFO:__main__:Stored batch 28 in MongoDB with key 'pmtest:jsonls:batch_28'\n",
      "INFO:__main__:Processing batch 30/373\n",
      "INFO:__main__:Stored batch 29 in MongoDB with key 'pmtest:jsonls:batch_29'\n",
      "INFO:__main__:Processing batch 31/373\n",
      "INFO:__main__:Stored batch 30 in MongoDB with key 'pmtest:jsonls:batch_30'\n",
      "INFO:__main__:Processing batch 32/373\n",
      "INFO:__main__:Stored batch 31 in MongoDB with key 'pmtest:jsonls:batch_31'\n",
      "INFO:__main__:Processing batch 33/373\n",
      "INFO:__main__:Stored batch 32 in MongoDB with key 'pmtest:jsonls:batch_32'\n",
      "INFO:__main__:Processing batch 34/373\n",
      "INFO:__main__:Stored batch 33 in MongoDB with key 'pmtest:jsonls:batch_33'\n",
      "INFO:__main__:Processing batch 35/373\n",
      "INFO:__main__:Stored batch 34 in MongoDB with key 'pmtest:jsonls:batch_34'\n",
      "INFO:__main__:Processing batch 36/373\n",
      "INFO:__main__:Stored batch 35 in MongoDB with key 'pmtest:jsonls:batch_35'\n",
      "INFO:__main__:Processing batch 37/373\n",
      "INFO:__main__:Stored batch 36 in MongoDB with key 'pmtest:jsonls:batch_36'\n",
      "INFO:__main__:Processing batch 38/373\n",
      "INFO:__main__:Stored batch 37 in MongoDB with key 'pmtest:jsonls:batch_37'\n",
      "INFO:__main__:Processing batch 39/373\n",
      "INFO:__main__:Stored batch 38 in MongoDB with key 'pmtest:jsonls:batch_38'\n",
      "INFO:__main__:Processing batch 40/373\n",
      "INFO:__main__:Stored batch 39 in MongoDB with key 'pmtest:jsonls:batch_39'\n",
      "INFO:__main__:Processing batch 41/373\n",
      "INFO:__main__:Stored batch 40 in MongoDB with key 'pmtest:jsonls:batch_40'\n",
      "INFO:__main__:Processing batch 42/373\n",
      "INFO:__main__:Stored batch 41 in MongoDB with key 'pmtest:jsonls:batch_41'\n",
      "INFO:__main__:Processing batch 43/373\n",
      "INFO:__main__:Stored batch 42 in MongoDB with key 'pmtest:jsonls:batch_42'\n",
      "INFO:__main__:Processing batch 44/373\n",
      "INFO:__main__:Stored batch 43 in MongoDB with key 'pmtest:jsonls:batch_43'\n",
      "INFO:__main__:Processing batch 45/373\n",
      "INFO:__main__:Stored batch 44 in MongoDB with key 'pmtest:jsonls:batch_44'\n",
      "INFO:__main__:Processing batch 46/373\n",
      "INFO:__main__:Stored batch 45 in MongoDB with key 'pmtest:jsonls:batch_45'\n",
      "INFO:__main__:Processing batch 47/373\n",
      "INFO:__main__:Stored batch 46 in MongoDB with key 'pmtest:jsonls:batch_46'\n",
      "INFO:__main__:Processing batch 48/373\n",
      "INFO:__main__:Stored batch 47 in MongoDB with key 'pmtest:jsonls:batch_47'\n",
      "INFO:__main__:Processing batch 49/373\n",
      "INFO:__main__:Stored batch 48 in MongoDB with key 'pmtest:jsonls:batch_48'\n",
      "INFO:__main__:Processing batch 50/373\n",
      "INFO:__main__:Stored batch 49 in MongoDB with key 'pmtest:jsonls:batch_49'\n",
      "INFO:__main__:Processing batch 51/373\n",
      "INFO:__main__:Stored batch 50 in MongoDB with key 'pmtest:jsonls:batch_50'\n",
      "INFO:__main__:Processing batch 52/373\n",
      "INFO:__main__:Stored batch 51 in MongoDB with key 'pmtest:jsonls:batch_51'\n",
      "INFO:__main__:Processing batch 53/373\n",
      "INFO:__main__:Stored batch 52 in MongoDB with key 'pmtest:jsonls:batch_52'\n",
      "INFO:__main__:Processing batch 54/373\n",
      "INFO:__main__:Stored batch 53 in MongoDB with key 'pmtest:jsonls:batch_53'\n",
      "INFO:__main__:Processing batch 55/373\n",
      "INFO:__main__:Stored batch 54 in MongoDB with key 'pmtest:jsonls:batch_54'\n",
      "INFO:__main__:Processing batch 56/373\n",
      "INFO:__main__:Stored batch 55 in MongoDB with key 'pmtest:jsonls:batch_55'\n",
      "INFO:__main__:Processing batch 57/373\n",
      "INFO:__main__:Stored batch 56 in MongoDB with key 'pmtest:jsonls:batch_56'\n",
      "INFO:__main__:Processing batch 58/373\n",
      "INFO:__main__:Stored batch 57 in MongoDB with key 'pmtest:jsonls:batch_57'\n",
      "INFO:__main__:Processing batch 59/373\n",
      "INFO:__main__:Stored batch 58 in MongoDB with key 'pmtest:jsonls:batch_58'\n",
      "INFO:__main__:Processing batch 60/373\n",
      "INFO:__main__:Stored batch 59 in MongoDB with key 'pmtest:jsonls:batch_59'\n",
      "INFO:__main__:Processing batch 61/373\n",
      "INFO:__main__:Stored batch 60 in MongoDB with key 'pmtest:jsonls:batch_60'\n",
      "INFO:__main__:Processing batch 62/373\n",
      "INFO:__main__:Stored batch 61 in MongoDB with key 'pmtest:jsonls:batch_61'\n",
      "INFO:__main__:Processing batch 63/373\n",
      "INFO:__main__:Stored batch 62 in MongoDB with key 'pmtest:jsonls:batch_62'\n",
      "INFO:__main__:Processing batch 64/373\n",
      "INFO:__main__:Stored batch 63 in MongoDB with key 'pmtest:jsonls:batch_63'\n",
      "INFO:__main__:Processing batch 65/373\n",
      "INFO:__main__:Stored batch 64 in MongoDB with key 'pmtest:jsonls:batch_64'\n",
      "INFO:__main__:Processing batch 66/373\n",
      "INFO:__main__:Stored batch 65 in MongoDB with key 'pmtest:jsonls:batch_65'\n",
      "INFO:__main__:Processing batch 67/373\n",
      "INFO:__main__:Stored batch 66 in MongoDB with key 'pmtest:jsonls:batch_66'\n",
      "INFO:__main__:Processing batch 68/373\n",
      "INFO:__main__:Stored batch 67 in MongoDB with key 'pmtest:jsonls:batch_67'\n",
      "INFO:__main__:Processing batch 69/373\n",
      "INFO:__main__:Stored batch 68 in MongoDB with key 'pmtest:jsonls:batch_68'\n",
      "INFO:__main__:Processing batch 70/373\n",
      "INFO:__main__:Stored batch 69 in MongoDB with key 'pmtest:jsonls:batch_69'\n",
      "INFO:__main__:Processing batch 71/373\n",
      "INFO:__main__:Stored batch 70 in MongoDB with key 'pmtest:jsonls:batch_70'\n",
      "INFO:__main__:Processing batch 72/373\n",
      "INFO:__main__:Stored batch 71 in MongoDB with key 'pmtest:jsonls:batch_71'\n",
      "INFO:__main__:Processing batch 73/373\n",
      "INFO:__main__:Stored batch 72 in MongoDB with key 'pmtest:jsonls:batch_72'\n",
      "INFO:__main__:Processing batch 74/373\n",
      "INFO:__main__:Stored batch 73 in MongoDB with key 'pmtest:jsonls:batch_73'\n",
      "INFO:__main__:Processing batch 75/373\n",
      "INFO:__main__:Stored batch 74 in MongoDB with key 'pmtest:jsonls:batch_74'\n",
      "INFO:__main__:Processing batch 76/373\n",
      "INFO:__main__:Stored batch 75 in MongoDB with key 'pmtest:jsonls:batch_75'\n",
      "INFO:__main__:Processing batch 77/373\n",
      "INFO:__main__:Stored batch 76 in MongoDB with key 'pmtest:jsonls:batch_76'\n",
      "INFO:__main__:Processing batch 78/373\n",
      "INFO:__main__:Stored batch 77 in MongoDB with key 'pmtest:jsonls:batch_77'\n",
      "INFO:__main__:Processing batch 79/373\n",
      "INFO:__main__:Stored batch 78 in MongoDB with key 'pmtest:jsonls:batch_78'\n",
      "INFO:__main__:Processing batch 80/373\n",
      "INFO:__main__:Stored batch 79 in MongoDB with key 'pmtest:jsonls:batch_79'\n",
      "INFO:__main__:Processing batch 81/373\n",
      "INFO:__main__:Stored batch 80 in MongoDB with key 'pmtest:jsonls:batch_80'\n",
      "INFO:__main__:Processing batch 82/373\n",
      "INFO:__main__:Stored batch 81 in MongoDB with key 'pmtest:jsonls:batch_81'\n",
      "INFO:__main__:Processing batch 83/373\n",
      "INFO:__main__:Stored batch 82 in MongoDB with key 'pmtest:jsonls:batch_82'\n",
      "INFO:__main__:Processing batch 84/373\n",
      "INFO:__main__:Stored batch 83 in MongoDB with key 'pmtest:jsonls:batch_83'\n",
      "INFO:__main__:Processing batch 85/373\n",
      "INFO:__main__:Stored batch 84 in MongoDB with key 'pmtest:jsonls:batch_84'\n",
      "INFO:__main__:Processing batch 86/373\n",
      "INFO:__main__:Stored batch 85 in MongoDB with key 'pmtest:jsonls:batch_85'\n",
      "INFO:__main__:Processing batch 87/373\n",
      "INFO:__main__:Stored batch 86 in MongoDB with key 'pmtest:jsonls:batch_86'\n",
      "INFO:__main__:Processing batch 88/373\n",
      "INFO:__main__:Stored batch 87 in MongoDB with key 'pmtest:jsonls:batch_87'\n",
      "INFO:__main__:Processing batch 89/373\n",
      "INFO:__main__:Stored batch 88 in MongoDB with key 'pmtest:jsonls:batch_88'\n",
      "INFO:__main__:Processing batch 90/373\n",
      "INFO:__main__:Stored batch 89 in MongoDB with key 'pmtest:jsonls:batch_89'\n",
      "INFO:__main__:Processing batch 91/373\n",
      "INFO:__main__:Stored batch 90 in MongoDB with key 'pmtest:jsonls:batch_90'\n",
      "INFO:__main__:Processing batch 92/373\n",
      "INFO:__main__:Stored batch 91 in MongoDB with key 'pmtest:jsonls:batch_91'\n",
      "INFO:__main__:Processing batch 93/373\n",
      "INFO:__main__:Stored batch 92 in MongoDB with key 'pmtest:jsonls:batch_92'\n",
      "INFO:__main__:Processing batch 94/373\n",
      "INFO:__main__:Stored batch 93 in MongoDB with key 'pmtest:jsonls:batch_93'\n",
      "INFO:__main__:Processing batch 95/373\n",
      "INFO:__main__:Stored batch 94 in MongoDB with key 'pmtest:jsonls:batch_94'\n",
      "INFO:__main__:Processing batch 96/373\n",
      "INFO:__main__:Stored batch 95 in MongoDB with key 'pmtest:jsonls:batch_95'\n",
      "INFO:__main__:Processing batch 97/373\n",
      "INFO:__main__:Stored batch 96 in MongoDB with key 'pmtest:jsonls:batch_96'\n",
      "INFO:__main__:Processing batch 98/373\n",
      "INFO:__main__:Stored batch 97 in MongoDB with key 'pmtest:jsonls:batch_97'\n",
      "INFO:__main__:Processing batch 99/373\n",
      "INFO:__main__:Stored batch 98 in MongoDB with key 'pmtest:jsonls:batch_98'\n",
      "INFO:__main__:Processing batch 100/373\n",
      "INFO:__main__:Stored batch 99 in MongoDB with key 'pmtest:jsonls:batch_99'\n",
      "INFO:__main__:Processing batch 101/373\n",
      "INFO:__main__:Stored batch 100 in MongoDB with key 'pmtest:jsonls:batch_100'\n",
      "INFO:__main__:Processing batch 102/373\n",
      "INFO:__main__:Stored batch 101 in MongoDB with key 'pmtest:jsonls:batch_101'\n",
      "INFO:__main__:Processing batch 103/373\n",
      "INFO:__main__:Stored batch 102 in MongoDB with key 'pmtest:jsonls:batch_102'\n",
      "INFO:__main__:Processing batch 104/373\n",
      "INFO:__main__:Stored batch 103 in MongoDB with key 'pmtest:jsonls:batch_103'\n",
      "INFO:__main__:Processing batch 105/373\n",
      "INFO:__main__:Stored batch 104 in MongoDB with key 'pmtest:jsonls:batch_104'\n",
      "INFO:__main__:Processing batch 106/373\n",
      "INFO:__main__:Stored batch 105 in MongoDB with key 'pmtest:jsonls:batch_105'\n",
      "INFO:__main__:Processing batch 107/373\n",
      "INFO:__main__:Stored batch 106 in MongoDB with key 'pmtest:jsonls:batch_106'\n",
      "INFO:__main__:Processing batch 108/373\n",
      "INFO:__main__:Stored batch 107 in MongoDB with key 'pmtest:jsonls:batch_107'\n",
      "INFO:__main__:Processing batch 109/373\n",
      "INFO:__main__:Stored batch 108 in MongoDB with key 'pmtest:jsonls:batch_108'\n",
      "INFO:__main__:Processing batch 110/373\n",
      "INFO:__main__:Stored batch 109 in MongoDB with key 'pmtest:jsonls:batch_109'\n",
      "INFO:__main__:Processing batch 111/373\n",
      "INFO:__main__:Stored batch 110 in MongoDB with key 'pmtest:jsonls:batch_110'\n",
      "INFO:__main__:Processing batch 112/373\n",
      "INFO:__main__:Stored batch 111 in MongoDB with key 'pmtest:jsonls:batch_111'\n",
      "INFO:__main__:Processing batch 113/373\n",
      "INFO:__main__:Stored batch 112 in MongoDB with key 'pmtest:jsonls:batch_112'\n",
      "INFO:__main__:Processing batch 114/373\n",
      "INFO:__main__:Stored batch 113 in MongoDB with key 'pmtest:jsonls:batch_113'\n",
      "INFO:__main__:Processing batch 115/373\n",
      "INFO:__main__:Stored batch 114 in MongoDB with key 'pmtest:jsonls:batch_114'\n",
      "INFO:__main__:Processing batch 116/373\n",
      "INFO:__main__:Stored batch 115 in MongoDB with key 'pmtest:jsonls:batch_115'\n",
      "INFO:__main__:Processing batch 117/373\n",
      "INFO:__main__:Stored batch 116 in MongoDB with key 'pmtest:jsonls:batch_116'\n",
      "INFO:__main__:Processing batch 118/373\n",
      "INFO:__main__:Stored batch 117 in MongoDB with key 'pmtest:jsonls:batch_117'\n",
      "INFO:__main__:Processing batch 119/373\n",
      "INFO:__main__:Stored batch 118 in MongoDB with key 'pmtest:jsonls:batch_118'\n",
      "INFO:__main__:Processing batch 120/373\n",
      "INFO:__main__:Stored batch 119 in MongoDB with key 'pmtest:jsonls:batch_119'\n",
      "INFO:__main__:Processing batch 121/373\n",
      "INFO:__main__:Stored batch 120 in MongoDB with key 'pmtest:jsonls:batch_120'\n",
      "INFO:__main__:Processing batch 122/373\n",
      "INFO:__main__:Stored batch 121 in MongoDB with key 'pmtest:jsonls:batch_121'\n",
      "INFO:__main__:Processing batch 123/373\n",
      "INFO:__main__:Stored batch 122 in MongoDB with key 'pmtest:jsonls:batch_122'\n",
      "INFO:__main__:Processing batch 124/373\n",
      "INFO:__main__:Stored batch 123 in MongoDB with key 'pmtest:jsonls:batch_123'\n",
      "INFO:__main__:Processing batch 125/373\n",
      "INFO:__main__:Stored batch 124 in MongoDB with key 'pmtest:jsonls:batch_124'\n",
      "INFO:__main__:Processing batch 126/373\n",
      "INFO:__main__:Stored batch 125 in MongoDB with key 'pmtest:jsonls:batch_125'\n",
      "INFO:__main__:Processing batch 127/373\n",
      "INFO:__main__:Stored batch 126 in MongoDB with key 'pmtest:jsonls:batch_126'\n",
      "INFO:__main__:Processing batch 128/373\n",
      "INFO:__main__:Stored batch 127 in MongoDB with key 'pmtest:jsonls:batch_127'\n",
      "INFO:__main__:Processing batch 129/373\n",
      "INFO:__main__:Stored batch 128 in MongoDB with key 'pmtest:jsonls:batch_128'\n",
      "INFO:__main__:Processing batch 130/373\n",
      "INFO:__main__:Stored batch 129 in MongoDB with key 'pmtest:jsonls:batch_129'\n",
      "INFO:__main__:Processing batch 131/373\n",
      "INFO:__main__:Stored batch 130 in MongoDB with key 'pmtest:jsonls:batch_130'\n",
      "INFO:__main__:Processing batch 132/373\n",
      "INFO:__main__:Stored batch 131 in MongoDB with key 'pmtest:jsonls:batch_131'\n",
      "INFO:__main__:Processing batch 133/373\n",
      "INFO:__main__:Stored batch 132 in MongoDB with key 'pmtest:jsonls:batch_132'\n",
      "INFO:__main__:Processing batch 134/373\n",
      "INFO:__main__:Stored batch 133 in MongoDB with key 'pmtest:jsonls:batch_133'\n",
      "INFO:__main__:Processing batch 135/373\n",
      "INFO:__main__:Stored batch 134 in MongoDB with key 'pmtest:jsonls:batch_134'\n",
      "INFO:__main__:Processing batch 136/373\n",
      "INFO:__main__:Stored batch 135 in MongoDB with key 'pmtest:jsonls:batch_135'\n",
      "INFO:__main__:Processing batch 137/373\n",
      "INFO:__main__:Stored batch 136 in MongoDB with key 'pmtest:jsonls:batch_136'\n",
      "INFO:__main__:Processing batch 138/373\n",
      "INFO:__main__:Stored batch 137 in MongoDB with key 'pmtest:jsonls:batch_137'\n",
      "INFO:__main__:Processing batch 139/373\n",
      "INFO:__main__:Stored batch 138 in MongoDB with key 'pmtest:jsonls:batch_138'\n",
      "INFO:__main__:Processing batch 140/373\n",
      "INFO:__main__:Stored batch 139 in MongoDB with key 'pmtest:jsonls:batch_139'\n",
      "INFO:__main__:Processing batch 141/373\n",
      "INFO:__main__:Stored batch 140 in MongoDB with key 'pmtest:jsonls:batch_140'\n",
      "INFO:__main__:Processing batch 142/373\n",
      "INFO:__main__:Stored batch 141 in MongoDB with key 'pmtest:jsonls:batch_141'\n",
      "INFO:__main__:Processing batch 143/373\n",
      "INFO:__main__:Stored batch 142 in MongoDB with key 'pmtest:jsonls:batch_142'\n",
      "INFO:__main__:Processing batch 144/373\n",
      "INFO:__main__:Stored batch 143 in MongoDB with key 'pmtest:jsonls:batch_143'\n",
      "INFO:__main__:Processing batch 145/373\n",
      "INFO:__main__:Stored batch 144 in MongoDB with key 'pmtest:jsonls:batch_144'\n",
      "INFO:__main__:Processing batch 146/373\n",
      "INFO:__main__:Stored batch 145 in MongoDB with key 'pmtest:jsonls:batch_145'\n",
      "INFO:__main__:Processing batch 147/373\n",
      "INFO:__main__:Stored batch 146 in MongoDB with key 'pmtest:jsonls:batch_146'\n",
      "INFO:__main__:Processing batch 148/373\n",
      "INFO:__main__:Stored batch 147 in MongoDB with key 'pmtest:jsonls:batch_147'\n",
      "INFO:__main__:Processing batch 149/373\n",
      "INFO:__main__:Stored batch 148 in MongoDB with key 'pmtest:jsonls:batch_148'\n",
      "INFO:__main__:Processing batch 150/373\n",
      "INFO:__main__:Stored batch 149 in MongoDB with key 'pmtest:jsonls:batch_149'\n",
      "INFO:__main__:Processing batch 151/373\n",
      "INFO:__main__:Stored batch 150 in MongoDB with key 'pmtest:jsonls:batch_150'\n",
      "INFO:__main__:Processing batch 152/373\n",
      "INFO:__main__:Stored batch 151 in MongoDB with key 'pmtest:jsonls:batch_151'\n",
      "INFO:__main__:Processing batch 153/373\n",
      "INFO:__main__:Stored batch 152 in MongoDB with key 'pmtest:jsonls:batch_152'\n",
      "INFO:__main__:Processing batch 154/373\n",
      "INFO:__main__:Stored batch 153 in MongoDB with key 'pmtest:jsonls:batch_153'\n",
      "INFO:__main__:Processing batch 155/373\n",
      "INFO:__main__:Stored batch 154 in MongoDB with key 'pmtest:jsonls:batch_154'\n",
      "INFO:__main__:Processing batch 156/373\n",
      "INFO:__main__:Stored batch 155 in MongoDB with key 'pmtest:jsonls:batch_155'\n",
      "INFO:__main__:Processing batch 157/373\n",
      "INFO:__main__:Stored batch 156 in MongoDB with key 'pmtest:jsonls:batch_156'\n",
      "INFO:__main__:Processing batch 158/373\n",
      "INFO:__main__:Stored batch 157 in MongoDB with key 'pmtest:jsonls:batch_157'\n",
      "INFO:__main__:Processing batch 159/373\n",
      "INFO:__main__:Stored batch 158 in MongoDB with key 'pmtest:jsonls:batch_158'\n",
      "INFO:__main__:Processing batch 160/373\n",
      "INFO:__main__:Stored batch 159 in MongoDB with key 'pmtest:jsonls:batch_159'\n",
      "INFO:__main__:Processing batch 161/373\n",
      "INFO:__main__:Stored batch 160 in MongoDB with key 'pmtest:jsonls:batch_160'\n",
      "INFO:__main__:Processing batch 162/373\n",
      "INFO:__main__:Stored batch 161 in MongoDB with key 'pmtest:jsonls:batch_161'\n",
      "INFO:__main__:Processing batch 163/373\n",
      "INFO:__main__:Stored batch 162 in MongoDB with key 'pmtest:jsonls:batch_162'\n",
      "INFO:__main__:Processing batch 164/373\n",
      "INFO:__main__:Stored batch 163 in MongoDB with key 'pmtest:jsonls:batch_163'\n",
      "INFO:__main__:Processing batch 165/373\n",
      "INFO:__main__:Stored batch 164 in MongoDB with key 'pmtest:jsonls:batch_164'\n",
      "INFO:__main__:Processing batch 166/373\n",
      "INFO:__main__:Stored batch 165 in MongoDB with key 'pmtest:jsonls:batch_165'\n",
      "INFO:__main__:Processing batch 167/373\n",
      "INFO:__main__:Stored batch 166 in MongoDB with key 'pmtest:jsonls:batch_166'\n",
      "INFO:__main__:Processing batch 168/373\n",
      "INFO:__main__:Stored batch 167 in MongoDB with key 'pmtest:jsonls:batch_167'\n",
      "INFO:__main__:Processing batch 169/373\n",
      "INFO:__main__:Stored batch 168 in MongoDB with key 'pmtest:jsonls:batch_168'\n",
      "INFO:__main__:Processing batch 170/373\n",
      "INFO:__main__:Stored batch 169 in MongoDB with key 'pmtest:jsonls:batch_169'\n",
      "INFO:__main__:Processing batch 171/373\n",
      "INFO:__main__:Stored batch 170 in MongoDB with key 'pmtest:jsonls:batch_170'\n",
      "INFO:__main__:Processing batch 172/373\n",
      "INFO:__main__:Stored batch 171 in MongoDB with key 'pmtest:jsonls:batch_171'\n",
      "INFO:__main__:Processing batch 173/373\n",
      "INFO:__main__:Stored batch 172 in MongoDB with key 'pmtest:jsonls:batch_172'\n",
      "INFO:__main__:Processing batch 174/373\n",
      "INFO:__main__:Stored batch 173 in MongoDB with key 'pmtest:jsonls:batch_173'\n",
      "INFO:__main__:Processing batch 175/373\n",
      "INFO:__main__:Stored batch 174 in MongoDB with key 'pmtest:jsonls:batch_174'\n",
      "INFO:__main__:Processing batch 176/373\n",
      "INFO:__main__:Stored batch 175 in MongoDB with key 'pmtest:jsonls:batch_175'\n",
      "INFO:__main__:Processing batch 177/373\n",
      "INFO:__main__:Stored batch 176 in MongoDB with key 'pmtest:jsonls:batch_176'\n",
      "INFO:__main__:Processing batch 178/373\n",
      "INFO:__main__:Stored batch 177 in MongoDB with key 'pmtest:jsonls:batch_177'\n",
      "INFO:__main__:Processing batch 179/373\n",
      "INFO:__main__:Stored batch 178 in MongoDB with key 'pmtest:jsonls:batch_178'\n",
      "INFO:__main__:Processing batch 180/373\n",
      "INFO:__main__:Stored batch 179 in MongoDB with key 'pmtest:jsonls:batch_179'\n",
      "INFO:__main__:Processing batch 181/373\n",
      "INFO:__main__:Stored batch 180 in MongoDB with key 'pmtest:jsonls:batch_180'\n",
      "INFO:__main__:Processing batch 182/373\n",
      "INFO:__main__:Stored batch 181 in MongoDB with key 'pmtest:jsonls:batch_181'\n",
      "INFO:__main__:Processing batch 183/373\n",
      "INFO:__main__:Stored batch 182 in MongoDB with key 'pmtest:jsonls:batch_182'\n",
      "INFO:__main__:Processing batch 184/373\n",
      "INFO:__main__:Stored batch 183 in MongoDB with key 'pmtest:jsonls:batch_183'\n",
      "INFO:__main__:Processing batch 185/373\n",
      "INFO:__main__:Stored batch 184 in MongoDB with key 'pmtest:jsonls:batch_184'\n",
      "INFO:__main__:Processing batch 186/373\n",
      "INFO:__main__:Stored batch 185 in MongoDB with key 'pmtest:jsonls:batch_185'\n",
      "INFO:__main__:Processing batch 187/373\n",
      "INFO:__main__:Stored batch 186 in MongoDB with key 'pmtest:jsonls:batch_186'\n",
      "INFO:__main__:Processing batch 188/373\n",
      "INFO:__main__:Stored batch 187 in MongoDB with key 'pmtest:jsonls:batch_187'\n",
      "INFO:__main__:Processing batch 189/373\n",
      "INFO:__main__:Stored batch 188 in MongoDB with key 'pmtest:jsonls:batch_188'\n",
      "INFO:__main__:Processing batch 190/373\n",
      "INFO:__main__:Stored batch 189 in MongoDB with key 'pmtest:jsonls:batch_189'\n",
      "INFO:__main__:Processing batch 191/373\n",
      "INFO:__main__:Stored batch 190 in MongoDB with key 'pmtest:jsonls:batch_190'\n",
      "INFO:__main__:Processing batch 192/373\n",
      "INFO:__main__:Stored batch 191 in MongoDB with key 'pmtest:jsonls:batch_191'\n",
      "INFO:__main__:Processing batch 193/373\n",
      "INFO:__main__:Stored batch 192 in MongoDB with key 'pmtest:jsonls:batch_192'\n",
      "INFO:__main__:Processing batch 194/373\n",
      "INFO:__main__:Stored batch 193 in MongoDB with key 'pmtest:jsonls:batch_193'\n",
      "INFO:__main__:Processing batch 195/373\n",
      "INFO:__main__:Stored batch 194 in MongoDB with key 'pmtest:jsonls:batch_194'\n",
      "INFO:__main__:Processing batch 196/373\n",
      "INFO:__main__:Stored batch 195 in MongoDB with key 'pmtest:jsonls:batch_195'\n",
      "INFO:__main__:Processing batch 197/373\n",
      "INFO:__main__:Stored batch 196 in MongoDB with key 'pmtest:jsonls:batch_196'\n",
      "INFO:__main__:Processing batch 198/373\n",
      "INFO:__main__:Stored batch 197 in MongoDB with key 'pmtest:jsonls:batch_197'\n",
      "INFO:__main__:Processing batch 199/373\n",
      "INFO:__main__:Stored batch 198 in MongoDB with key 'pmtest:jsonls:batch_198'\n",
      "INFO:__main__:Processing batch 200/373\n",
      "INFO:__main__:Stored batch 199 in MongoDB with key 'pmtest:jsonls:batch_199'\n",
      "INFO:__main__:Processing batch 201/373\n",
      "INFO:__main__:Stored batch 200 in MongoDB with key 'pmtest:jsonls:batch_200'\n",
      "INFO:__main__:Processing batch 202/373\n",
      "INFO:__main__:Stored batch 201 in MongoDB with key 'pmtest:jsonls:batch_201'\n",
      "INFO:__main__:Processing batch 203/373\n",
      "INFO:__main__:Stored batch 202 in MongoDB with key 'pmtest:jsonls:batch_202'\n",
      "INFO:__main__:Processing batch 204/373\n",
      "INFO:__main__:Stored batch 203 in MongoDB with key 'pmtest:jsonls:batch_203'\n",
      "INFO:__main__:Processing batch 205/373\n",
      "INFO:__main__:Stored batch 204 in MongoDB with key 'pmtest:jsonls:batch_204'\n",
      "INFO:__main__:Processing batch 206/373\n",
      "INFO:__main__:Stored batch 205 in MongoDB with key 'pmtest:jsonls:batch_205'\n",
      "INFO:__main__:Processing batch 207/373\n",
      "INFO:__main__:Stored batch 206 in MongoDB with key 'pmtest:jsonls:batch_206'\n",
      "INFO:__main__:Processing batch 208/373\n",
      "INFO:__main__:Stored batch 207 in MongoDB with key 'pmtest:jsonls:batch_207'\n",
      "INFO:__main__:Processing batch 209/373\n",
      "INFO:__main__:Stored batch 208 in MongoDB with key 'pmtest:jsonls:batch_208'\n",
      "INFO:__main__:Processing batch 210/373\n",
      "INFO:__main__:Stored batch 209 in MongoDB with key 'pmtest:jsonls:batch_209'\n",
      "INFO:__main__:Processing batch 211/373\n",
      "INFO:__main__:Stored batch 210 in MongoDB with key 'pmtest:jsonls:batch_210'\n",
      "INFO:__main__:Processing batch 212/373\n",
      "INFO:__main__:Stored batch 211 in MongoDB with key 'pmtest:jsonls:batch_211'\n",
      "INFO:__main__:Processing batch 213/373\n",
      "INFO:__main__:Stored batch 212 in MongoDB with key 'pmtest:jsonls:batch_212'\n",
      "INFO:__main__:Processing batch 214/373\n",
      "INFO:__main__:Stored batch 213 in MongoDB with key 'pmtest:jsonls:batch_213'\n",
      "INFO:__main__:Processing batch 215/373\n",
      "INFO:__main__:Stored batch 214 in MongoDB with key 'pmtest:jsonls:batch_214'\n",
      "INFO:__main__:Processing batch 216/373\n",
      "INFO:__main__:Stored batch 215 in MongoDB with key 'pmtest:jsonls:batch_215'\n",
      "INFO:__main__:Processing batch 217/373\n",
      "INFO:__main__:Stored batch 216 in MongoDB with key 'pmtest:jsonls:batch_216'\n",
      "INFO:__main__:Processing batch 218/373\n",
      "INFO:__main__:Stored batch 217 in MongoDB with key 'pmtest:jsonls:batch_217'\n",
      "INFO:__main__:Processing batch 219/373\n",
      "INFO:__main__:Stored batch 218 in MongoDB with key 'pmtest:jsonls:batch_218'\n",
      "INFO:__main__:Processing batch 220/373\n",
      "INFO:__main__:Stored batch 219 in MongoDB with key 'pmtest:jsonls:batch_219'\n",
      "INFO:__main__:Processing batch 221/373\n",
      "INFO:__main__:Stored batch 220 in MongoDB with key 'pmtest:jsonls:batch_220'\n",
      "INFO:__main__:Processing batch 222/373\n",
      "INFO:__main__:Stored batch 221 in MongoDB with key 'pmtest:jsonls:batch_221'\n",
      "INFO:__main__:Processing batch 223/373\n",
      "INFO:__main__:Stored batch 222 in MongoDB with key 'pmtest:jsonls:batch_222'\n",
      "INFO:__main__:Processing batch 224/373\n",
      "INFO:__main__:Stored batch 223 in MongoDB with key 'pmtest:jsonls:batch_223'\n",
      "INFO:__main__:Processing batch 225/373\n",
      "INFO:__main__:Stored batch 224 in MongoDB with key 'pmtest:jsonls:batch_224'\n",
      "INFO:__main__:Processing batch 226/373\n",
      "INFO:__main__:Stored batch 225 in MongoDB with key 'pmtest:jsonls:batch_225'\n",
      "INFO:__main__:Processing batch 227/373\n",
      "INFO:__main__:Stored batch 226 in MongoDB with key 'pmtest:jsonls:batch_226'\n",
      "INFO:__main__:Processing batch 228/373\n",
      "INFO:__main__:Stored batch 227 in MongoDB with key 'pmtest:jsonls:batch_227'\n",
      "INFO:__main__:Processing batch 229/373\n",
      "INFO:__main__:Stored batch 228 in MongoDB with key 'pmtest:jsonls:batch_228'\n",
      "INFO:__main__:Processing batch 230/373\n",
      "INFO:__main__:Stored batch 229 in MongoDB with key 'pmtest:jsonls:batch_229'\n",
      "INFO:__main__:Processing batch 231/373\n",
      "INFO:__main__:Stored batch 230 in MongoDB with key 'pmtest:jsonls:batch_230'\n",
      "INFO:__main__:Processing batch 232/373\n",
      "INFO:__main__:Stored batch 231 in MongoDB with key 'pmtest:jsonls:batch_231'\n",
      "INFO:__main__:Processing batch 233/373\n",
      "INFO:__main__:Stored batch 232 in MongoDB with key 'pmtest:jsonls:batch_232'\n",
      "INFO:__main__:Processing batch 234/373\n",
      "INFO:__main__:Stored batch 233 in MongoDB with key 'pmtest:jsonls:batch_233'\n",
      "INFO:__main__:Processing batch 235/373\n",
      "INFO:__main__:Stored batch 234 in MongoDB with key 'pmtest:jsonls:batch_234'\n",
      "INFO:__main__:Processing batch 236/373\n",
      "INFO:__main__:Stored batch 235 in MongoDB with key 'pmtest:jsonls:batch_235'\n",
      "INFO:__main__:Processing batch 237/373\n",
      "INFO:__main__:Stored batch 236 in MongoDB with key 'pmtest:jsonls:batch_236'\n",
      "INFO:__main__:Processing batch 238/373\n",
      "INFO:__main__:Stored batch 237 in MongoDB with key 'pmtest:jsonls:batch_237'\n",
      "INFO:__main__:Processing batch 239/373\n",
      "INFO:__main__:Stored batch 238 in MongoDB with key 'pmtest:jsonls:batch_238'\n",
      "INFO:__main__:Processing batch 240/373\n",
      "INFO:__main__:Stored batch 239 in MongoDB with key 'pmtest:jsonls:batch_239'\n",
      "INFO:__main__:Processing batch 241/373\n",
      "INFO:__main__:Stored batch 240 in MongoDB with key 'pmtest:jsonls:batch_240'\n",
      "INFO:__main__:Processing batch 242/373\n",
      "INFO:__main__:Stored batch 241 in MongoDB with key 'pmtest:jsonls:batch_241'\n",
      "INFO:__main__:Processing batch 243/373\n",
      "INFO:__main__:Stored batch 242 in MongoDB with key 'pmtest:jsonls:batch_242'\n",
      "INFO:__main__:Processing batch 244/373\n",
      "INFO:__main__:Stored batch 243 in MongoDB with key 'pmtest:jsonls:batch_243'\n",
      "INFO:__main__:Processing batch 245/373\n",
      "INFO:__main__:Stored batch 244 in MongoDB with key 'pmtest:jsonls:batch_244'\n",
      "INFO:__main__:Processing batch 246/373\n",
      "INFO:__main__:Stored batch 245 in MongoDB with key 'pmtest:jsonls:batch_245'\n",
      "INFO:__main__:Processing batch 247/373\n",
      "INFO:__main__:Stored batch 246 in MongoDB with key 'pmtest:jsonls:batch_246'\n",
      "INFO:__main__:Processing batch 248/373\n",
      "INFO:__main__:Stored batch 247 in MongoDB with key 'pmtest:jsonls:batch_247'\n",
      "INFO:__main__:Processing batch 249/373\n",
      "INFO:__main__:Stored batch 248 in MongoDB with key 'pmtest:jsonls:batch_248'\n",
      "INFO:__main__:Processing batch 250/373\n",
      "INFO:__main__:Stored batch 249 in MongoDB with key 'pmtest:jsonls:batch_249'\n",
      "INFO:__main__:Processing batch 251/373\n",
      "INFO:__main__:Stored batch 250 in MongoDB with key 'pmtest:jsonls:batch_250'\n",
      "INFO:__main__:Processing batch 252/373\n",
      "INFO:__main__:Stored batch 251 in MongoDB with key 'pmtest:jsonls:batch_251'\n",
      "INFO:__main__:Processing batch 253/373\n",
      "INFO:__main__:Stored batch 252 in MongoDB with key 'pmtest:jsonls:batch_252'\n",
      "INFO:__main__:Processing batch 254/373\n",
      "INFO:__main__:Stored batch 253 in MongoDB with key 'pmtest:jsonls:batch_253'\n",
      "INFO:__main__:Processing batch 255/373\n",
      "INFO:__main__:Stored batch 254 in MongoDB with key 'pmtest:jsonls:batch_254'\n",
      "INFO:__main__:Processing batch 256/373\n",
      "INFO:__main__:Stored batch 255 in MongoDB with key 'pmtest:jsonls:batch_255'\n",
      "INFO:__main__:Processing batch 257/373\n",
      "INFO:__main__:Stored batch 256 in MongoDB with key 'pmtest:jsonls:batch_256'\n",
      "INFO:__main__:Processing batch 258/373\n",
      "INFO:__main__:Stored batch 257 in MongoDB with key 'pmtest:jsonls:batch_257'\n",
      "INFO:__main__:Processing batch 259/373\n",
      "INFO:__main__:Stored batch 258 in MongoDB with key 'pmtest:jsonls:batch_258'\n",
      "INFO:__main__:Processing batch 260/373\n",
      "INFO:__main__:Stored batch 259 in MongoDB with key 'pmtest:jsonls:batch_259'\n",
      "INFO:__main__:Processing batch 261/373\n",
      "INFO:__main__:Stored batch 260 in MongoDB with key 'pmtest:jsonls:batch_260'\n",
      "INFO:__main__:Processing batch 262/373\n",
      "INFO:__main__:Stored batch 261 in MongoDB with key 'pmtest:jsonls:batch_261'\n",
      "INFO:__main__:Processing batch 263/373\n",
      "INFO:__main__:Stored batch 262 in MongoDB with key 'pmtest:jsonls:batch_262'\n",
      "INFO:__main__:Processing batch 264/373\n",
      "INFO:__main__:Stored batch 263 in MongoDB with key 'pmtest:jsonls:batch_263'\n",
      "INFO:__main__:Processing batch 265/373\n",
      "INFO:__main__:Stored batch 264 in MongoDB with key 'pmtest:jsonls:batch_264'\n",
      "INFO:__main__:Processing batch 266/373\n",
      "INFO:__main__:Stored batch 265 in MongoDB with key 'pmtest:jsonls:batch_265'\n",
      "INFO:__main__:Processing batch 267/373\n",
      "INFO:__main__:Stored batch 266 in MongoDB with key 'pmtest:jsonls:batch_266'\n",
      "INFO:__main__:Processing batch 268/373\n",
      "INFO:__main__:Stored batch 267 in MongoDB with key 'pmtest:jsonls:batch_267'\n",
      "INFO:__main__:Processing batch 269/373\n",
      "INFO:__main__:Stored batch 268 in MongoDB with key 'pmtest:jsonls:batch_268'\n",
      "INFO:__main__:Processing batch 270/373\n",
      "INFO:__main__:Stored batch 269 in MongoDB with key 'pmtest:jsonls:batch_269'\n",
      "INFO:__main__:Processing batch 271/373\n",
      "INFO:__main__:Stored batch 270 in MongoDB with key 'pmtest:jsonls:batch_270'\n",
      "INFO:__main__:Processing batch 272/373\n",
      "INFO:__main__:Stored batch 271 in MongoDB with key 'pmtest:jsonls:batch_271'\n",
      "INFO:__main__:Processing batch 273/373\n",
      "INFO:__main__:Stored batch 272 in MongoDB with key 'pmtest:jsonls:batch_272'\n",
      "INFO:__main__:Processing batch 274/373\n",
      "INFO:__main__:Stored batch 273 in MongoDB with key 'pmtest:jsonls:batch_273'\n",
      "INFO:__main__:Processing batch 275/373\n",
      "INFO:__main__:Stored batch 274 in MongoDB with key 'pmtest:jsonls:batch_274'\n",
      "INFO:__main__:Processing batch 276/373\n",
      "INFO:__main__:Stored batch 275 in MongoDB with key 'pmtest:jsonls:batch_275'\n",
      "INFO:__main__:Processing batch 277/373\n",
      "INFO:__main__:Stored batch 276 in MongoDB with key 'pmtest:jsonls:batch_276'\n",
      "INFO:__main__:Processing batch 278/373\n",
      "INFO:__main__:Stored batch 277 in MongoDB with key 'pmtest:jsonls:batch_277'\n",
      "INFO:__main__:Processing batch 279/373\n",
      "INFO:__main__:Stored batch 278 in MongoDB with key 'pmtest:jsonls:batch_278'\n",
      "INFO:__main__:Processing batch 280/373\n",
      "INFO:__main__:Stored batch 279 in MongoDB with key 'pmtest:jsonls:batch_279'\n",
      "INFO:__main__:Processing batch 281/373\n",
      "INFO:__main__:Stored batch 280 in MongoDB with key 'pmtest:jsonls:batch_280'\n",
      "INFO:__main__:Processing batch 282/373\n",
      "INFO:__main__:Stored batch 281 in MongoDB with key 'pmtest:jsonls:batch_281'\n",
      "INFO:__main__:Processing batch 283/373\n",
      "INFO:__main__:Stored batch 282 in MongoDB with key 'pmtest:jsonls:batch_282'\n",
      "INFO:__main__:Processing batch 284/373\n",
      "INFO:__main__:Stored batch 283 in MongoDB with key 'pmtest:jsonls:batch_283'\n",
      "INFO:__main__:Processing batch 285/373\n",
      "INFO:__main__:Stored batch 284 in MongoDB with key 'pmtest:jsonls:batch_284'\n",
      "INFO:__main__:Processing batch 286/373\n",
      "INFO:__main__:Stored batch 285 in MongoDB with key 'pmtest:jsonls:batch_285'\n",
      "INFO:__main__:Processing batch 287/373\n",
      "INFO:__main__:Stored batch 286 in MongoDB with key 'pmtest:jsonls:batch_286'\n",
      "INFO:__main__:Processing batch 288/373\n",
      "INFO:__main__:Stored batch 287 in MongoDB with key 'pmtest:jsonls:batch_287'\n",
      "INFO:__main__:Processing batch 289/373\n",
      "INFO:__main__:Stored batch 288 in MongoDB with key 'pmtest:jsonls:batch_288'\n",
      "INFO:__main__:Processing batch 290/373\n",
      "INFO:__main__:Stored batch 289 in MongoDB with key 'pmtest:jsonls:batch_289'\n",
      "INFO:__main__:Processing batch 291/373\n",
      "INFO:__main__:Stored batch 290 in MongoDB with key 'pmtest:jsonls:batch_290'\n",
      "INFO:__main__:Processing batch 292/373\n",
      "INFO:__main__:Stored batch 291 in MongoDB with key 'pmtest:jsonls:batch_291'\n",
      "INFO:__main__:Processing batch 293/373\n",
      "INFO:__main__:Stored batch 292 in MongoDB with key 'pmtest:jsonls:batch_292'\n",
      "INFO:__main__:Processing batch 294/373\n",
      "INFO:__main__:Stored batch 293 in MongoDB with key 'pmtest:jsonls:batch_293'\n",
      "INFO:__main__:Processing batch 295/373\n",
      "INFO:__main__:Stored batch 294 in MongoDB with key 'pmtest:jsonls:batch_294'\n",
      "INFO:__main__:Processing batch 296/373\n",
      "INFO:__main__:Stored batch 295 in MongoDB with key 'pmtest:jsonls:batch_295'\n",
      "INFO:__main__:Processing batch 297/373\n",
      "INFO:__main__:Stored batch 296 in MongoDB with key 'pmtest:jsonls:batch_296'\n",
      "INFO:__main__:Processing batch 298/373\n",
      "INFO:__main__:Stored batch 297 in MongoDB with key 'pmtest:jsonls:batch_297'\n",
      "INFO:__main__:Processing batch 299/373\n",
      "INFO:__main__:Stored batch 298 in MongoDB with key 'pmtest:jsonls:batch_298'\n",
      "INFO:__main__:Processing batch 300/373\n",
      "INFO:__main__:Stored batch 299 in MongoDB with key 'pmtest:jsonls:batch_299'\n",
      "INFO:__main__:Processing batch 301/373\n",
      "INFO:__main__:Stored batch 300 in MongoDB with key 'pmtest:jsonls:batch_300'\n",
      "INFO:__main__:Processing batch 302/373\n",
      "INFO:__main__:Stored batch 301 in MongoDB with key 'pmtest:jsonls:batch_301'\n",
      "INFO:__main__:Processing batch 303/373\n",
      "INFO:__main__:Stored batch 302 in MongoDB with key 'pmtest:jsonls:batch_302'\n",
      "INFO:__main__:Processing batch 304/373\n",
      "INFO:__main__:Stored batch 303 in MongoDB with key 'pmtest:jsonls:batch_303'\n",
      "INFO:__main__:Processing batch 305/373\n",
      "INFO:__main__:Stored batch 304 in MongoDB with key 'pmtest:jsonls:batch_304'\n",
      "INFO:__main__:Processing batch 306/373\n",
      "INFO:__main__:Stored batch 305 in MongoDB with key 'pmtest:jsonls:batch_305'\n",
      "INFO:__main__:Processing batch 307/373\n",
      "INFO:__main__:Stored batch 306 in MongoDB with key 'pmtest:jsonls:batch_306'\n",
      "INFO:__main__:Processing batch 308/373\n",
      "INFO:__main__:Stored batch 307 in MongoDB with key 'pmtest:jsonls:batch_307'\n",
      "INFO:__main__:Processing batch 309/373\n",
      "INFO:__main__:Stored batch 308 in MongoDB with key 'pmtest:jsonls:batch_308'\n",
      "INFO:__main__:Processing batch 310/373\n",
      "INFO:__main__:Stored batch 309 in MongoDB with key 'pmtest:jsonls:batch_309'\n",
      "INFO:__main__:Processing batch 311/373\n",
      "INFO:__main__:Stored batch 310 in MongoDB with key 'pmtest:jsonls:batch_310'\n",
      "INFO:__main__:Processing batch 312/373\n",
      "INFO:__main__:Stored batch 311 in MongoDB with key 'pmtest:jsonls:batch_311'\n",
      "INFO:__main__:Processing batch 313/373\n",
      "INFO:__main__:Stored batch 312 in MongoDB with key 'pmtest:jsonls:batch_312'\n",
      "INFO:__main__:Processing batch 314/373\n",
      "INFO:__main__:Stored batch 313 in MongoDB with key 'pmtest:jsonls:batch_313'\n",
      "INFO:__main__:Processing batch 315/373\n",
      "INFO:__main__:Stored batch 314 in MongoDB with key 'pmtest:jsonls:batch_314'\n",
      "INFO:__main__:Processing batch 316/373\n",
      "INFO:__main__:Stored batch 315 in MongoDB with key 'pmtest:jsonls:batch_315'\n",
      "INFO:__main__:Processing batch 317/373\n",
      "INFO:__main__:Stored batch 316 in MongoDB with key 'pmtest:jsonls:batch_316'\n",
      "INFO:__main__:Processing batch 318/373\n",
      "INFO:__main__:Stored batch 317 in MongoDB with key 'pmtest:jsonls:batch_317'\n",
      "INFO:__main__:Processing batch 319/373\n",
      "INFO:__main__:Stored batch 318 in MongoDB with key 'pmtest:jsonls:batch_318'\n",
      "INFO:__main__:Processing batch 320/373\n",
      "INFO:__main__:Stored batch 319 in MongoDB with key 'pmtest:jsonls:batch_319'\n",
      "INFO:__main__:Processing batch 321/373\n",
      "INFO:__main__:Stored batch 320 in MongoDB with key 'pmtest:jsonls:batch_320'\n",
      "INFO:__main__:Processing batch 322/373\n",
      "INFO:__main__:Stored batch 321 in MongoDB with key 'pmtest:jsonls:batch_321'\n",
      "INFO:__main__:Processing batch 323/373\n",
      "INFO:__main__:Stored batch 322 in MongoDB with key 'pmtest:jsonls:batch_322'\n",
      "INFO:__main__:Processing batch 324/373\n",
      "INFO:__main__:Stored batch 323 in MongoDB with key 'pmtest:jsonls:batch_323'\n",
      "INFO:__main__:Processing batch 325/373\n",
      "INFO:__main__:Stored batch 324 in MongoDB with key 'pmtest:jsonls:batch_324'\n",
      "INFO:__main__:Processing batch 326/373\n",
      "INFO:__main__:Stored batch 325 in MongoDB with key 'pmtest:jsonls:batch_325'\n",
      "INFO:__main__:Processing batch 327/373\n",
      "INFO:__main__:Stored batch 326 in MongoDB with key 'pmtest:jsonls:batch_326'\n",
      "INFO:__main__:Processing batch 328/373\n",
      "INFO:__main__:Stored batch 327 in MongoDB with key 'pmtest:jsonls:batch_327'\n",
      "INFO:__main__:Processing batch 329/373\n",
      "INFO:__main__:Stored batch 328 in MongoDB with key 'pmtest:jsonls:batch_328'\n",
      "INFO:__main__:Processing batch 330/373\n",
      "INFO:__main__:Stored batch 329 in MongoDB with key 'pmtest:jsonls:batch_329'\n",
      "INFO:__main__:Processing batch 331/373\n",
      "INFO:__main__:Stored batch 330 in MongoDB with key 'pmtest:jsonls:batch_330'\n",
      "INFO:__main__:Processing batch 332/373\n",
      "INFO:__main__:Stored batch 331 in MongoDB with key 'pmtest:jsonls:batch_331'\n",
      "INFO:__main__:Processing batch 333/373\n",
      "INFO:__main__:Stored batch 332 in MongoDB with key 'pmtest:jsonls:batch_332'\n",
      "INFO:__main__:Processing batch 334/373\n",
      "INFO:__main__:Stored batch 333 in MongoDB with key 'pmtest:jsonls:batch_333'\n",
      "INFO:__main__:Processing batch 335/373\n",
      "INFO:__main__:Stored batch 334 in MongoDB with key 'pmtest:jsonls:batch_334'\n",
      "INFO:__main__:Processing batch 336/373\n",
      "INFO:__main__:Stored batch 335 in MongoDB with key 'pmtest:jsonls:batch_335'\n",
      "INFO:__main__:Processing batch 337/373\n",
      "INFO:__main__:Stored batch 336 in MongoDB with key 'pmtest:jsonls:batch_336'\n",
      "INFO:__main__:Processing batch 338/373\n",
      "INFO:__main__:Stored batch 337 in MongoDB with key 'pmtest:jsonls:batch_337'\n",
      "INFO:__main__:Processing batch 339/373\n",
      "INFO:__main__:Stored batch 338 in MongoDB with key 'pmtest:jsonls:batch_338'\n",
      "INFO:__main__:Processing batch 340/373\n",
      "INFO:__main__:Stored batch 339 in MongoDB with key 'pmtest:jsonls:batch_339'\n",
      "INFO:__main__:Processing batch 341/373\n",
      "INFO:__main__:Stored batch 340 in MongoDB with key 'pmtest:jsonls:batch_340'\n",
      "INFO:__main__:Processing batch 342/373\n",
      "INFO:__main__:Stored batch 341 in MongoDB with key 'pmtest:jsonls:batch_341'\n",
      "INFO:__main__:Processing batch 343/373\n",
      "INFO:__main__:Stored batch 342 in MongoDB with key 'pmtest:jsonls:batch_342'\n",
      "INFO:__main__:Processing batch 344/373\n",
      "INFO:__main__:Stored batch 343 in MongoDB with key 'pmtest:jsonls:batch_343'\n",
      "INFO:__main__:Processing batch 345/373\n",
      "INFO:__main__:Stored batch 344 in MongoDB with key 'pmtest:jsonls:batch_344'\n",
      "INFO:__main__:Processing batch 346/373\n",
      "INFO:__main__:Stored batch 345 in MongoDB with key 'pmtest:jsonls:batch_345'\n",
      "INFO:__main__:Processing batch 347/373\n",
      "INFO:__main__:Stored batch 346 in MongoDB with key 'pmtest:jsonls:batch_346'\n",
      "INFO:__main__:Processing batch 348/373\n",
      "INFO:__main__:Stored batch 347 in MongoDB with key 'pmtest:jsonls:batch_347'\n",
      "INFO:__main__:Processing batch 349/373\n",
      "INFO:__main__:Stored batch 348 in MongoDB with key 'pmtest:jsonls:batch_348'\n",
      "INFO:__main__:Processing batch 350/373\n",
      "INFO:__main__:Stored batch 349 in MongoDB with key 'pmtest:jsonls:batch_349'\n",
      "INFO:__main__:Processing batch 351/373\n",
      "INFO:__main__:Stored batch 350 in MongoDB with key 'pmtest:jsonls:batch_350'\n",
      "INFO:__main__:Processing batch 352/373\n",
      "INFO:__main__:Stored batch 351 in MongoDB with key 'pmtest:jsonls:batch_351'\n",
      "INFO:__main__:Processing batch 353/373\n",
      "INFO:__main__:Stored batch 352 in MongoDB with key 'pmtest:jsonls:batch_352'\n",
      "INFO:__main__:Processing batch 354/373\n",
      "INFO:__main__:Stored batch 353 in MongoDB with key 'pmtest:jsonls:batch_353'\n",
      "INFO:__main__:Processing batch 355/373\n",
      "INFO:__main__:Stored batch 354 in MongoDB with key 'pmtest:jsonls:batch_354'\n",
      "INFO:__main__:Processing batch 356/373\n",
      "INFO:__main__:Stored batch 355 in MongoDB with key 'pmtest:jsonls:batch_355'\n",
      "INFO:__main__:Processing batch 357/373\n",
      "INFO:__main__:Stored batch 356 in MongoDB with key 'pmtest:jsonls:batch_356'\n",
      "INFO:__main__:Processing batch 358/373\n",
      "INFO:__main__:Stored batch 357 in MongoDB with key 'pmtest:jsonls:batch_357'\n",
      "INFO:__main__:Processing batch 359/373\n",
      "INFO:__main__:Stored batch 358 in MongoDB with key 'pmtest:jsonls:batch_358'\n",
      "INFO:__main__:Processing batch 360/373\n",
      "INFO:__main__:Stored batch 359 in MongoDB with key 'pmtest:jsonls:batch_359'\n",
      "INFO:__main__:Processing batch 361/373\n",
      "INFO:__main__:Stored batch 360 in MongoDB with key 'pmtest:jsonls:batch_360'\n",
      "INFO:__main__:Processing batch 362/373\n",
      "INFO:__main__:Stored batch 361 in MongoDB with key 'pmtest:jsonls:batch_361'\n",
      "INFO:__main__:Processing batch 363/373\n",
      "INFO:__main__:Stored batch 362 in MongoDB with key 'pmtest:jsonls:batch_362'\n",
      "INFO:__main__:Processing batch 364/373\n",
      "INFO:__main__:Stored batch 363 in MongoDB with key 'pmtest:jsonls:batch_363'\n",
      "INFO:__main__:Processing batch 365/373\n",
      "INFO:__main__:Stored batch 364 in MongoDB with key 'pmtest:jsonls:batch_364'\n",
      "INFO:__main__:Processing batch 366/373\n",
      "INFO:__main__:Stored batch 365 in MongoDB with key 'pmtest:jsonls:batch_365'\n",
      "INFO:__main__:Processing batch 367/373\n",
      "INFO:__main__:Stored batch 366 in MongoDB with key 'pmtest:jsonls:batch_366'\n",
      "INFO:__main__:Processing batch 368/373\n",
      "INFO:__main__:Stored batch 367 in MongoDB with key 'pmtest:jsonls:batch_367'\n",
      "INFO:__main__:Processing batch 369/373\n",
      "INFO:__main__:Stored batch 368 in MongoDB with key 'pmtest:jsonls:batch_368'\n",
      "INFO:__main__:Processing batch 370/373\n",
      "INFO:__main__:Stored batch 369 in MongoDB with key 'pmtest:jsonls:batch_369'\n",
      "INFO:__main__:Processing batch 371/373\n",
      "INFO:__main__:Stored batch 370 in MongoDB with key 'pmtest:jsonls:batch_370'\n",
      "INFO:__main__:Processing batch 372/373\n",
      "INFO:__main__:Stored batch 371 in MongoDB with key 'pmtest:jsonls:batch_371'\n",
      "INFO:__main__:Processing batch 373/373\n",
      "INFO:__main__:Stored batch 372 in MongoDB with key 'pmtest:jsonls:batch_372'\n",
      "INFO:__main__:Stored all batches in MongoDB.\n",
      "INFO:__main__:Created OpenAI files and stored batch data in MongoDB!\n",
      "INFO:__main__:\n",
      "Sample output from first batch:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"custom_id\": \"request_text_EP3157302A1_5113165\", \"method\": \"POST\", \"url\": \"/v1/chat/completions\", \"body\": {\"model\": \"gpt-4-turbo-preview\", \"messages\": [{\"role\": \"system\", \"content\": \"Analyze the text for negations and identify their types.\"}, {\"role\": \"user\", \"content\": \"Analyze the following text: A network of handling a paging procedure in a wireless communication system the network comprising a storage unit 210 for storing instructions and a processing circuit 200 coupled to the storage unit 210 wherein the storage unit 210 stores and the processing circuit 200 is configured to execute the instructions of receiving a first Non Access Stratum NAS message comprising a first time interval for monitoring a paging occasion and a second time interval for monitoring the paging occasion from a communication device wherein the second time interval is larger than the first time interval transmitting a second NAS message comprising a third time interval for monitoring the paging occasion to the communication device and storing the first time interval and the third time interval after receiving the first NAS message wherein the third time interval is larger than the first time interval performing the paging procedure by using the third time interval when a packet data network PDN connection for an emergency bearer service is not established or not establishing and performing the paging procedure by using the first time interval when the PDN connection for the emergency bearer service is established or establishing.\"}], \"response_format\": {\"type\": \"json_schema\", \"json_schema\": {\"name\": \"negation_response\", \"schema\": {\"properties\": {\"negation_present\": {\"title\": \"Negation Present\", \"type\": \"boolean\"}, \"negation_types\": {\"anyOf\": [{\"items\": {\"type\": \"string\"}, \"type\": \"array\"}, {\"type\": \"null\"}], \"title\": \"Negation Types\"}, \"short_explanation\": {\"title\": \"Short Explanation\", \"type\": \"string\"}}, \"required\": [\"negation_present\", \"negation_types\", \"short_explanation\"], \"title\": \"NegationResponse\", \"type\": \"object\"}}}, \"max_tokens\": 500}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "import json\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from typing import List, Optional\n",
    "from pydantic import BaseModel\n",
    "from tqdm import tqdm\n",
    "from pymongo import MongoClient  # Use PyMongo instead of redis\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Define the NegationResponse model\n",
    "class NegationResponse(BaseModel):\n",
    "    negation_present: bool\n",
    "    negation_types: Optional[List[str]]\n",
    "    short_explanation: str\n",
    "\n",
    "# Create output directory\n",
    "output_dir = Path('output_jsonl')\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Connect to MongoDB using your provided configuration\n",
    "# Note: the connection string includes the root username, password, and database name.\n",
    "client = MongoClient(\"mongodb://user:pass@localhost:27017/admin\")\n",
    "db = client.test_negationdb\n",
    "collection = db.jsonl_batches  # Use a collection named \"jsonl_batches\"\n",
    "\n",
    "# Process in smaller batches\n",
    "batch_size = 1000\n",
    "num_batches = len(df) // batch_size + 1  # assuming df is your DataFrame\n",
    "\n",
    "def create_jsonl_line(row, column):\n",
    "    text = row[column]\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"Analyze the text for negations and identify their types.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Analyze the following text: {text}\"}\n",
    "    ]\n",
    "    \n",
    "    body = {\n",
    "        \"model\": \"gpt-4-turbo-preview\",\n",
    "        \"messages\": messages,\n",
    "        \"response_format\": {\n",
    "            \"type\": \"json_schema\",\n",
    "            \"json_schema\": {\n",
    "                \"name\": \"negation_response\",\n",
    "                \"schema\": NegationResponse.model_json_schema()\n",
    "            }\n",
    "        },\n",
    "        \"max_tokens\": 500\n",
    "    }\n",
    "    \n",
    "    return {\n",
    "        \"custom_id\": f'request_{column}_{row[\"patent_application_id\"]}_{row[\"index\"]}',\n",
    "        \"method\": \"POST\",\n",
    "        \"url\": \"/v1/chat/completions\",\n",
    "        \"body\": body\n",
    "    }\n",
    "\n",
    "# Process batches and store each batch both on disk and in MongoDB\n",
    "openai_files_disk_dump = []\n",
    "for i in range(num_batches):\n",
    "    start_idx = i * batch_size\n",
    "    end_idx = min((i + 1) * batch_size, len(df))\n",
    "    batch_df = df.iloc[start_idx:end_idx]\n",
    "    \n",
    "    logger.info(f\"Processing batch {i + 1}/{num_batches}\")\n",
    "    lines = batch_df.apply(create_jsonl_line, axis=1, args=('text',))\n",
    "    \n",
    "    # Write batch to disk as a JSONL file\n",
    "    batch_file_path = output_dir / f\"batch_{i}.jsonl\"\n",
    "    with open(batch_file_path, \"w\", encoding='utf-8') as f:\n",
    "        for line in lines:\n",
    "            f.write(json.dumps(line, ensure_ascii=False) + \"\\n\")\n",
    "    \n",
    "    # Prepare data for MongoDB storage\n",
    "    batch_data = [json.loads(json.dumps(line)) for line in lines]  # ensure serializable\n",
    "    batch_document = {\n",
    "        \"batch_key\": f\"pmtest:jsonls:batch_{i}\",\n",
    "        \"batch_index\": i,\n",
    "        \"data\": batch_data\n",
    "    }\n",
    "    collection.insert_one(batch_document)\n",
    "    logger.info(f\"Stored batch {i} in MongoDB with key 'pmtest:jsonls:batch_{i}'\")\n",
    "    \n",
    "    # Record disk dump info\n",
    "    openai_files_disk_dump.append({\n",
    "        \"json_path\": str(batch_file_path),\n",
    "        \"batch_index\": i\n",
    "    })\n",
    "\n",
    "logger.info(\"Stored all batches in MongoDB.\")\n",
    "\n",
    "# Write the disk dump info to disk\n",
    "openai_files_disk_dump_path = output_dir / \"openai_files_disk_dump.json\"\n",
    "with open(openai_files_disk_dump_path, \"w\", encoding='utf-8') as f:\n",
    "    f.write(json.dumps(openai_files_disk_dump))\n",
    "    \n",
    "logger.info(\"Created OpenAI files and stored batch data in MongoDB!\")\n",
    "\n",
    "# Show sample output from the first batch\n",
    "logger.info(\"\\nSample output from first batch:\")\n",
    "with open(output_dir / \"batch_0.jsonl\", \"r\", encoding='utf-8') as f:\n",
    "    print(f.readline())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:openai._base_client:Retrying request to /files in 0.478061 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import asyncio\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import openai\n",
    "from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception, after_log\n",
    "import aio_pika\n",
    "import aiofiles\n",
    "from motor.motor_asyncio import AsyncIOMotorClient\n",
    "\n",
    "# --- Logging Setup ---\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# --- Global Concurrency Limit ---\n",
    "CONCURRENCY_LIMIT = 20\n",
    "semaphore = asyncio.Semaphore(CONCURRENCY_LIMIT)\n",
    "\n",
    "# --- Global Variables ---\n",
    "GLOBAL_EXCHANGE = None\n",
    "ASYNC_CLIENT = None  # Async OpenAI client\n",
    "MONGO_CLIENT = None\n",
    "DB = None\n",
    "FILES_COLLECTION = None  # For files API responses\n",
    "BATCHES_COLLECTION = None  # For batch API responses\n",
    "\n",
    "# --- OpenAI API Key and Async Client ---\n",
    "openai_api_key = os.getenv(\"THESIS_ALON_OPENAI_API_KEY\")\n",
    "if not openai_api_key:\n",
    "    raise ValueError(\"Please set the THESIS_ALON_OPENAI_API_KEY environment variable.\")\n",
    "ASYNC_CLIENT = openai.AsyncOpenAI(api_key=openai_api_key)\n",
    "\n",
    "# --- RabbitMQ Connection Details ---\n",
    "RABBITMQ_URL = \"amqp://admin:password@localhost:5672/\"\n",
    "\n",
    "# --- MongoDB Connection Details ---\n",
    "MONGO_URI = \"mongodb://localhost:27017\"\n",
    "MONGO_DB_NAME = \"test_negationdb\"\n",
    "\n",
    "# --- Directory with Files ---\n",
    "batch_files_dir = Path(r'C:\\Users\\orgrd\\workspace\\repos\\runi-thesis-project\\notebooks\\output_jsonl')\n",
    "\n",
    "# --- Exchange & Queue Names ---\n",
    "EXCHANGE_NAME = \"thesis\"\n",
    "DLX_NAME = \"thesis_dl\"\n",
    "UPLOAD_QUEUE = \"upload_queue\"\n",
    "BATCH_QUEUE = \"batch_queue\"\n",
    "COMPLETED_QUEUE = \"completed_queue\"\n",
    "\n",
    "# --- Retry Helper ---\n",
    "def is_rate_limit_error(exception):\n",
    "    err_str = str(exception)\n",
    "    return (\"rate_limit_exceeded\" in err_str or \n",
    "            \"10054\" in err_str or \n",
    "            \"502\" in err_str or \n",
    "            \"Bad Gateway\" in err_str)\n",
    "\n",
    "@retry(\n",
    "    stop=stop_after_attempt(10),\n",
    "    wait=wait_exponential(multiplier=3, min=5, max=120),\n",
    "    retry=retry_if_exception(is_rate_limit_error),\n",
    "    after=after_log(logger, logging.WARNING)\n",
    ")\n",
    "async def upload_file(file_path: Path):\n",
    "    \"\"\"\n",
    "    Upload a JSONL file to OpenAI using the async client and return metadata.\n",
    "    \"\"\"\n",
    "    logger.info(f\"Creating OpenAI file for {file_path}...\")\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        result = await ASYNC_CLIENT.files.create(file=f, purpose=\"batch\")\n",
    "    metadata = {\n",
    "        \"file_id\": result.id,\n",
    "        \"original_filename\": file_path.name,\n",
    "        \"status\": result.status,\n",
    "        \"created_at\": result.created_at,\n",
    "        \"upload_timestamp\": datetime.now().isoformat(),\n",
    "        \"bytes\": result.bytes,\n",
    "        \"purpose\": result.purpose\n",
    "    }\n",
    "    return metadata\n",
    "\n",
    "@retry(\n",
    "    stop=stop_after_attempt(10),\n",
    "    wait=wait_exponential(multiplier=3, min=5, max=120),\n",
    "    retry=retry_if_exception(is_rate_limit_error),\n",
    "    after=after_log(logger, logging.WARNING)\n",
    ")\n",
    "async def submit_batch_job(file_id: str):\n",
    "    \"\"\"\n",
    "    Create a batch job using the async OpenAI client.\n",
    "    Uses parameters as in your snippet.\n",
    "    \"\"\"\n",
    "    # Retrieve the file's original filename from MongoDB\n",
    "    file_record = await FILES_COLLECTION.find_one({\"file_id\": file_id})\n",
    "    original_filename = file_record.get(\"original_filename\", \"\") if file_record else \"\"\n",
    "    logger.info(f\"Creating batch for file {file_id} with original filename '{original_filename}'...\")\n",
    "    batch = await ASYNC_CLIENT.batches.create(\n",
    "        input_file_id=file_id,\n",
    "        endpoint=\"/v1/chat/completions\",\n",
    "        completion_window=\"24h\",\n",
    "        metadata={\"input_file\": original_filename},\n",
    "    )\n",
    "    return batch.id\n",
    "\n",
    "# --- Consumer Callbacks ---\n",
    "\n",
    "async def upload_consumer(message: aio_pika.IncomingMessage):\n",
    "    \"\"\"\n",
    "    Upload consumer: reads the file path from the message.\n",
    "    If a file record already exists in MongoDB (matching original_filename), skip re-upload.\n",
    "    Otherwise, upload the file to OpenAI, save metadata to MongoDB, and publish a minimal message with file id.\n",
    "    \"\"\"\n",
    "    async with semaphore:\n",
    "        async with message.process():\n",
    "            try:\n",
    "                payload = json.loads(message.body.decode())\n",
    "                file_path = Path(payload[\"file_path\"])\n",
    "                # Check if file already exists (by original_filename)\n",
    "                existing = await FILES_COLLECTION.find_one({\"original_filename\": file_path.name})\n",
    "                if existing:\n",
    "                    logger.info(f\"File {file_path.name} already uploaded with file_id {existing['file_id']}. Skipping upload.\")\n",
    "                    minimal_payload = {\"file_id\": existing[\"file_id\"]}\n",
    "                else:\n",
    "                    logger.info(f\"Uploading file: {file_path}\")\n",
    "                    metadata = await upload_file(file_path)\n",
    "                    logger.info(f\"Uploaded {file_path.name}, file_id: {metadata['file_id']}\")\n",
    "                    await FILES_COLLECTION.insert_one(metadata)\n",
    "                    minimal_payload = {\"file_id\": metadata[\"file_id\"]}\n",
    "                await GLOBAL_EXCHANGE.publish(\n",
    "                    aio_pika.Message(body=json.dumps(minimal_payload).encode()),\n",
    "                    routing_key=\"batch\"\n",
    "                )\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Upload failed: {e}\")\n",
    "                raise e\n",
    "\n",
    "async def batch_consumer(message: aio_pika.IncomingMessage):\n",
    "    \"\"\"\n",
    "    Batch consumer: receives a message with the file id.\n",
    "    If the file record already has a batch_id, skip creating a new batch.\n",
    "    Otherwise, create a batch using the async OpenAI client, update MongoDB, and publish a completion message.\n",
    "    \"\"\"\n",
    "    async with semaphore:\n",
    "        async with message.process():\n",
    "            try:\n",
    "                payload = json.loads(message.body.decode())\n",
    "                file_id = payload[\"file_id\"]\n",
    "                logger.info(f\"Processing batch for file_id: {file_id}\")\n",
    "                # Check if a batch has already been created\n",
    "                file_record = await FILES_COLLECTION.find_one({\"file_id\": file_id})\n",
    "                if file_record and file_record.get(\"batch_id\"):\n",
    "                    batch_id = file_record[\"batch_id\"]\n",
    "                    logger.info(f\"Batch already exists for file {file_id}: batch_id {batch_id}\")\n",
    "                else:\n",
    "                    batch_id = await submit_batch_job(file_id)\n",
    "                    logger.info(f\"Batch created for file {file_id}, batch_id: {batch_id}\")\n",
    "                    await FILES_COLLECTION.update_one({\"file_id\": file_id}, {\"$set\": {\"batch_id\": batch_id, \"status\": \"batch_created\", \"batch_timestamp\": datetime.now().isoformat()}})\n",
    "                    # Also, store batch record in a separate collection\n",
    "                    await BATCHES_COLLECTION.insert_one({\n",
    "                        \"file_id\": file_id,\n",
    "                        \"batch_id\": batch_id,\n",
    "                        \"created_at\": datetime.now().isoformat(),\n",
    "                        \"status\": \"batch_created\"\n",
    "                    })\n",
    "                completed_payload = {\"file_id\": file_id, \"batch_id\": batch_id}\n",
    "                await GLOBAL_EXCHANGE.publish(\n",
    "                    aio_pika.Message(body=json.dumps(completed_payload).encode()),\n",
    "                    routing_key=\"completed\"\n",
    "                )\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Batch creation failed for file {payload.get('file_id')}: {e}\")\n",
    "                raise e\n",
    "\n",
    "async def completed_consumer(message: aio_pika.IncomingMessage):\n",
    "    \"\"\"\n",
    "    Completed consumer: logs the completion and updates the file record in MongoDB.\n",
    "    \"\"\"\n",
    "    async with semaphore:\n",
    "        async with message.process():\n",
    "            payload = json.loads(message.body.decode())\n",
    "            file_id = payload[\"file_id\"]\n",
    "            batch_id = payload[\"batch_id\"]\n",
    "            logger.info(f\"Completed processing: file_id {file_id}, batch_id {batch_id}\")\n",
    "            await FILES_COLLECTION.update_one({\"file_id\": file_id}, {\"$set\": {\"status\": \"completed\", \"completed_timestamp\": datetime.now().isoformat()}})\n",
    "\n",
    "# --- Main Function: Setup Exchanges, Queues, Consumers, and Producers ---\n",
    "async def main():\n",
    "    global GLOBAL_EXCHANGE, MONGO_CLIENT, DB, FILES_COLLECTION, BATCHES_COLLECTION, ASYNC_CLIENT\n",
    "    # Connect to RabbitMQ\n",
    "    connection = await aio_pika.connect_robust(RABBITMQ_URL)\n",
    "    # Connect to MongoDB\n",
    "    MONGO_CLIENT = AsyncIOMotorClient(MONGO_URI)\n",
    "    DB = MONGO_CLIENT[MONGO_DB_NAME]\n",
    "    FILES_COLLECTION = DB.pmtest_files\n",
    "    BATCHES_COLLECTION = DB.pmtest_batches\n",
    "\n",
    "    async with connection:\n",
    "        channel = await connection.channel()\n",
    "        GLOBAL_EXCHANGE = await channel.declare_exchange(EXCHANGE_NAME, aio_pika.ExchangeType.DIRECT)\n",
    "        dlx = await channel.declare_exchange(DLX_NAME, aio_pika.ExchangeType.FANOUT)\n",
    "        upload_queue = await channel.declare_queue(UPLOAD_QUEUE, durable=True, arguments={\"x-dead-letter-exchange\": DLX_NAME})\n",
    "        batch_queue = await channel.declare_queue(BATCH_QUEUE, durable=True, arguments={\"x-dead-letter-exchange\": DLX_NAME})\n",
    "        completed_queue = await channel.declare_queue(COMPLETED_QUEUE, durable=True, arguments={\"x-dead-letter-exchange\": DLX_NAME})\n",
    "        dead_letter_queue = await channel.declare_queue(\"dead_letter_queue\", durable=True)\n",
    "        await dead_letter_queue.bind(dlx, routing_key=\"\")\n",
    "        await upload_queue.bind(GLOBAL_EXCHANGE, routing_key=\"upload\")\n",
    "        await batch_queue.bind(GLOBAL_EXCHANGE, routing_key=\"batch\")\n",
    "        await completed_queue.bind(GLOBAL_EXCHANGE, routing_key=\"completed\")\n",
    "        await upload_queue.consume(upload_consumer)\n",
    "        await batch_queue.consume(batch_consumer)\n",
    "        await completed_queue.consume(completed_consumer)\n",
    "        # Enqueue upload tasks for all JSONL files in the directory\n",
    "        for file in sorted(batch_files_dir.glob(\"batch_*.jsonl\")):\n",
    "            payload = {\"file_path\": str(file)}\n",
    "            await GLOBAL_EXCHANGE.publish(\n",
    "                aio_pika.Message(body=json.dumps(payload).encode()),\n",
    "                routing_key=\"upload\"\n",
    "            )\n",
    "            logger.info(f\"Enqueued upload task for {file.name}\")\n",
    "        logger.info(\"Pipeline is running. Press CTRL+C to exit.\")\n",
    "        await asyncio.Future()\n",
    "\n",
    "# Run the pipeline in the current event loop.\n",
    "await main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process OpenAI Batch Requests\n",
    "\n",
    "This section handles batch processing with OpenAI, including:\n",
    "1. Reading file IDs from tracking directory\n",
    "2. Managing batch submissions (max 50 concurrent batches)\n",
    "3. Tracking progress and handling errors\n",
    "4. Retrying failed requests\n",
    "5. Saving results as they arrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:aio_pika.robust_connection:Connection to amqp://admin:******@rabbitmq:5672/ closed. Reconnecting after 5 seconds.\n"
     ]
    },
    {
     "ename": "AMQPConnectionError",
     "evalue": "[Errno 11001] getaddrinfo failed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\orgrd\\workspace\\repos\\runi-thesis-project\\.venv\\Lib\\site-packages\\aiormq\\connection.py:457\u001b[0m, in \u001b[0;36mConnection.connect\u001b[1;34m(self, client_properties)\u001b[0m\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 457\u001b[0m     reader, writer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mopen_connection(\n\u001b[0;32m    458\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl\u001b[38;5;241m.\u001b[39mhost, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl\u001b[38;5;241m.\u001b[39mport, ssl\u001b[38;5;241m=\u001b[39mssl_context,\n\u001b[0;32m    459\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__create_connection_kwargs,\n\u001b[0;32m    460\u001b[0m     )\n\u001b[0;32m    462\u001b[0m     frame_receiver \u001b[38;5;241m=\u001b[39m FrameReceiver(reader)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\streams.py:48\u001b[0m, in \u001b[0;36mopen_connection\u001b[1;34m(host, port, limit, **kwds)\u001b[0m\n\u001b[0;32m     47\u001b[0m protocol \u001b[38;5;241m=\u001b[39m StreamReaderProtocol(reader, loop\u001b[38;5;241m=\u001b[39mloop)\n\u001b[1;32m---> 48\u001b[0m transport, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mcreate_connection(\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m: protocol, host, port, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     50\u001b[0m writer \u001b[38;5;241m=\u001b[39m StreamWriter(transport, protocol, reader, loop)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py:1046\u001b[0m, in \u001b[0;36mBaseEventLoop.create_connection\u001b[1;34m(self, protocol_factory, host, port, ssl, family, proto, flags, sock, local_addr, server_hostname, ssl_handshake_timeout, ssl_shutdown_timeout, happy_eyeballs_delay, interleave)\u001b[0m\n\u001b[0;32m   1043\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1044\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhost/port and sock can not be specified at the same time\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 1046\u001b[0m infos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_resolved(\n\u001b[0;32m   1047\u001b[0m     (host, port), family\u001b[38;5;241m=\u001b[39mfamily,\n\u001b[0;32m   1048\u001b[0m     \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39msocket\u001b[38;5;241m.\u001b[39mSOCK_STREAM, proto\u001b[38;5;241m=\u001b[39mproto, flags\u001b[38;5;241m=\u001b[39mflags, loop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m infos:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py:1420\u001b[0m, in \u001b[0;36mBaseEventLoop._ensure_resolved\u001b[1;34m(self, address, family, type, proto, flags, loop)\u001b[0m\n\u001b[0;32m   1419\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mgetaddrinfo(host, port, family\u001b[38;5;241m=\u001b[39mfamily, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtype\u001b[39m,\n\u001b[0;32m   1421\u001b[0m                                   proto\u001b[38;5;241m=\u001b[39mproto, flags\u001b[38;5;241m=\u001b[39mflags)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py:868\u001b[0m, in \u001b[0;36mBaseEventLoop.getaddrinfo\u001b[1;34m(self, host, port, family, type, proto, flags)\u001b[0m\n\u001b[0;32m    866\u001b[0m     getaddr_func \u001b[38;5;241m=\u001b[39m socket\u001b[38;5;241m.\u001b[39mgetaddrinfo\n\u001b[1;32m--> 868\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_in_executor(\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m, getaddr_func, host, port, family, \u001b[38;5;28mtype\u001b[39m, proto, flags)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\socket.py:962\u001b[0m, in \u001b[0;36mgetaddrinfo\u001b[1;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[0;32m    961\u001b[0m addrlist \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 962\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43m_socket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetaddrinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfamily\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproto\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    963\u001b[0m     af, socktype, proto, canonname, sa \u001b[38;5;241m=\u001b[39m res\n",
      "\u001b[1;31mgaierror\u001b[0m: [Errno 11001] getaddrinfo failed",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mAMQPConnectionError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 208\u001b[0m\n\u001b[0;32m    205\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mFuture()\n\u001b[0;32m    207\u001b[0m \u001b[38;5;66;03m# Run the main function\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m main()\n",
      "Cell \u001b[1;32mIn[19], line 156\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmain\u001b[39m():\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;66;03m# Connect to RabbitMQ\u001b[39;00m\n\u001b[1;32m--> 156\u001b[0m     connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m aio_pika\u001b[38;5;241m.\u001b[39mconnect_robust(RABBITMQ_URL)\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m connection:\n\u001b[0;32m    158\u001b[0m         channel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m connection\u001b[38;5;241m.\u001b[39mchannel()\n",
      "File \u001b[1;32mc:\\Users\\orgrd\\workspace\\repos\\runi-thesis-project\\.venv\\Lib\\site-packages\\aio_pika\\robust_connection.py:334\u001b[0m, in \u001b[0;36mconnect_robust\u001b[1;34m(url, host, port, login, password, virtualhost, ssl, loop, ssl_options, ssl_context, timeout, client_properties, connection_class, **kwargs)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Make connection to the broker.\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \n\u001b[0;32m    239\u001b[0m \u001b[38;5;124;03mExample:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    315\u001b[0m \n\u001b[0;32m    316\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    318\u001b[0m connection: AbstractRobustConnection \u001b[38;5;241m=\u001b[39m connection_class(\n\u001b[0;32m    319\u001b[0m     make_url(\n\u001b[0;32m    320\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    331\u001b[0m     loop\u001b[38;5;241m=\u001b[39mloop, ssl_context\u001b[38;5;241m=\u001b[39mssl_context, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    332\u001b[0m )\n\u001b[1;32m--> 334\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m connection\u001b[38;5;241m.\u001b[39mconnect(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    335\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m connection\n",
      "File \u001b[1;32mc:\\Users\\orgrd\\workspace\\repos\\runi-thesis-project\\.venv\\Lib\\site-packages\\aio_pika\\robust_connection.py:180\u001b[0m, in \u001b[0;36mRobustConnection.connect\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__reconnection_task:\n\u001b[0;32m    176\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__reconnection_task \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloop\u001b[38;5;241m.\u001b[39mcreate_task(\n\u001b[0;32m    177\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__connection_factory(),\n\u001b[0;32m    178\u001b[0m     )\n\u001b[1;32m--> 180\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__fail_fast_future\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnected\u001b[38;5;241m.\u001b[39mwait()\n",
      "File \u001b[1;32mc:\\Users\\orgrd\\workspace\\repos\\runi-thesis-project\\.venv\\Lib\\site-packages\\aio_pika\\robust_connection.py:135\u001b[0m, in \u001b[0;36mRobustConnection.__connection_factory\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnected\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m    134\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection attempt for \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 135\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m Connection\u001b[38;5;241m.\u001b[39mconnect(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__connect_timeout)\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__fail_fast_future\u001b[38;5;241m.\u001b[39mdone():\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__fail_fast_future\u001b[38;5;241m.\u001b[39mset_result(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\orgrd\\workspace\\repos\\runi-thesis-project\\.venv\\Lib\\site-packages\\aio_pika\\connection.py:125\u001b[0m, in \u001b[0;36mConnection.connect\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout: TimeoutType \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    117\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" Connect to AMQP server. This method should be called after\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;124;03m    :func:`aio_pika.connection.Connection.__init__`\u001b[39;00m\n\u001b[0;32m    119\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    123\u001b[0m \n\u001b[0;32m    124\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransport \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m UnderlayConnection\u001b[38;5;241m.\u001b[39mconnect(\n\u001b[0;32m    126\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_on_connection_close,\n\u001b[0;32m    127\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs,\n\u001b[0;32m    128\u001b[0m     )\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_on_connected()\n",
      "File \u001b[1;32mc:\\Users\\orgrd\\workspace\\repos\\runi-thesis-project\\.venv\\Lib\\site-packages\\aio_pika\\abc.py:679\u001b[0m, in \u001b[0;36mUnderlayConnection.connect\u001b[1;34m(cls, url, close_callback, timeout, **kwargs)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    674\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mconnect\u001b[39m(\n\u001b[0;32m    675\u001b[0m     \u001b[38;5;28mcls\u001b[39m, url: URL, close_callback: Callable[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, Awaitable[Any]],\n\u001b[0;32m    676\u001b[0m     timeout: TimeoutType \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    677\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnderlayConnection\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    678\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 679\u001b[0m         connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mmake_connection(\n\u001b[0;32m    680\u001b[0m             url, timeout\u001b[38;5;241m=\u001b[39mtimeout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    681\u001b[0m         )\n\u001b[0;32m    682\u001b[0m         close_callback \u001b[38;5;241m=\u001b[39m OneShotCallback(close_callback)\n\u001b[0;32m    683\u001b[0m         connection\u001b[38;5;241m.\u001b[39mclosing\u001b[38;5;241m.\u001b[39madd_done_callback(close_callback)\n",
      "File \u001b[1;32mc:\\Users\\orgrd\\workspace\\repos\\runi-thesis-project\\.venv\\Lib\\site-packages\\aio_pika\\abc.py:667\u001b[0m, in \u001b[0;36mUnderlayConnection.make_connection\u001b[1;34m(cls, url, timeout, **kwargs)\u001b[0m\n\u001b[0;32m    663\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    664\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmake_connection\u001b[39m(\n\u001b[0;32m    665\u001b[0m     \u001b[38;5;28mcls\u001b[39m, url: URL, timeout: TimeoutType \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    666\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m aiormq\u001b[38;5;241m.\u001b[39mabc\u001b[38;5;241m.\u001b[39mAbstractConnection:\n\u001b[1;32m--> 667\u001b[0m     connection: aiormq\u001b[38;5;241m.\u001b[39mabc\u001b[38;5;241m.\u001b[39mAbstractConnection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mwait_for(\n\u001b[0;32m    668\u001b[0m         aiormq\u001b[38;5;241m.\u001b[39mconnect(url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs), timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    669\u001b[0m     )\n\u001b[0;32m    670\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m connection\u001b[38;5;241m.\u001b[39mready()\n\u001b[0;32m    671\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m connection\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\tasks.py:452\u001b[0m, in \u001b[0;36mwait_for\u001b[1;34m(fut, timeout)\u001b[0m\n\u001b[0;32m    449\u001b[0m loop \u001b[38;5;241m=\u001b[39m events\u001b[38;5;241m.\u001b[39mget_running_loop()\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 452\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m fut\n\u001b[0;32m    454\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    455\u001b[0m     fut \u001b[38;5;241m=\u001b[39m ensure_future(fut, loop\u001b[38;5;241m=\u001b[39mloop)\n",
      "File \u001b[1;32mc:\\Users\\orgrd\\workspace\\repos\\runi-thesis-project\\.venv\\Lib\\site-packages\\aiormq\\connection.py:920\u001b[0m, in \u001b[0;36mconnect\u001b[1;34m(url, client_properties, *args, **kwargs)\u001b[0m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mconnect\u001b[39m(\n\u001b[0;32m    915\u001b[0m     url: URLorStr, \u001b[38;5;241m*\u001b[39margs: Any, client_properties: Optional[FieldTable] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    916\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    917\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AbstractConnection:\n\u001b[0;32m    918\u001b[0m     connection \u001b[38;5;241m=\u001b[39m Connection(url, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 920\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m connection\u001b[38;5;241m.\u001b[39mconnect(client_properties \u001b[38;5;129;01mor\u001b[39;00m {})\n\u001b[0;32m    921\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m connection\n",
      "File \u001b[1;32mc:\\Users\\orgrd\\workspace\\repos\\runi-thesis-project\\.venv\\Lib\\site-packages\\aiormq\\base.py:164\u001b[0m, in \u001b[0;36mtask.<locals>.wrap\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrap\u001b[39m(\u001b[38;5;28mself\u001b[39m: Base, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m--> 164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_task(func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n",
      "File \u001b[1;32mc:\\Users\\orgrd\\workspace\\repos\\runi-thesis-project\\.venv\\Lib\\site-packages\\aiormq\\abc.py:44\u001b[0m, in \u001b[0;36mTaskWrapper.__inner\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__inner\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 44\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mCancelledError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     46\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\orgrd\\workspace\\repos\\runi-thesis-project\\.venv\\Lib\\site-packages\\aiormq\\connection.py:464\u001b[0m, in \u001b[0;36mConnection.connect\u001b[1;34m(self, client_properties)\u001b[0m\n\u001b[0;32m    462\u001b[0m     frame_receiver \u001b[38;5;241m=\u001b[39m FrameReceiver(reader)\n\u001b[0;32m    463\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 464\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m AMQPConnectionError(\u001b[38;5;241m*\u001b[39me\u001b[38;5;241m.\u001b[39margs) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    466\u001b[0m frame: Optional[FrameTypes]\n\u001b[0;32m    468\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mAMQPConnectionError\u001b[0m: [Errno 11001] getaddrinfo failed"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception, after_log\n",
    "import aio_pika\n",
    "\n",
    "# --- Logging Setup ---\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.WARN)\n",
    "\n",
    "# --- RabbitMQ Connection Details ---\n",
    "# (Using the docker compose settings: username=admin, password=password, host=rabbitmq)\n",
    "RABBITMQ_URL = \"amqp://admin:password@rabbitmq:5672/\"\n",
    "\n",
    "# --- OpenAI API Key ---\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "if not api_key:\n",
    "    raise ValueError(\"Please set the OPENAI_API_KEY environment variable.\")\n",
    "\n",
    "# --- Directory with Files to Process ---\n",
    "output_dir = Path('output_jsonl')  # This folder should contain files matching \"batch_*.jsonl\"\n",
    "\n",
    "# --- Define Exchange and Queue Names ---\n",
    "EXCHANGE_NAME = \"thesis\"         # main exchange\n",
    "DLX_NAME = \"thesis_dl\"           # dead letter exchange\n",
    "UPLOAD_QUEUE = \"upload_queue\"\n",
    "BATCH_QUEUE = \"batch_queue\"\n",
    "COMPLETED_QUEUE = \"completed_queue\"\n",
    "\n",
    "# --- Retry Helpers for Rate Limits ---\n",
    "def is_rate_limit_error(exception):\n",
    "    return \"rate_limit_exceeded\" in str(exception)\n",
    "\n",
    "@retry(\n",
    "    after=after_log(logger, logging.WARN),\n",
    "    stop=stop_after_attempt(10),\n",
    "    wait=wait_exponential(multiplier=3, min=5, max=120),\n",
    "    retry=retry_if_exception(is_rate_limit_error)\n",
    ")\n",
    "async def submit_batch_job(session, file_id):\n",
    "    \"\"\"\n",
    "    Submit the uploaded file for batch processing.\n",
    "    Returns the batch_id on success.\n",
    "    \"\"\"\n",
    "    url = 'https://api.openai.com/v1/batches'\n",
    "    headers = {\n",
    "        'Authorization': f\"Bearer {api_key}\",\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "    data = {\n",
    "        'file_id': file_id,\n",
    "        'purpose': 'batch'\n",
    "    }\n",
    "    async with session.post(url, headers=headers, json=data) as response:\n",
    "        response_json = await response.json()\n",
    "        if response.status != 200:\n",
    "            error_message = response_json.get(\"error\", {}).get(\"message\", \"Unknown error\")\n",
    "            raise Exception(f\"Error submitting batch job for file {file_id}: {error_message}\")\n",
    "        batch_id = response_json.get('id')\n",
    "        if not batch_id:\n",
    "            raise Exception(f\"Received null batch_id for file {file_id}, retrying...\")\n",
    "        return batch_id\n",
    "\n",
    "@retry(\n",
    "    after=after_log(logger, logging.WARN),\n",
    "    stop=stop_after_attempt(10),\n",
    "    wait=wait_exponential(multiplier=3, min=5, max=120),\n",
    "    retry=retry_if_exception(is_rate_limit_error)\n",
    ")\n",
    "async def upload_file(session, file_path: Path):\n",
    "    \"\"\"\n",
    "    Upload a file to OpenAI and return the file_id along with metadata.\n",
    "    \"\"\"\n",
    "    url = 'https://api.openai.com/v1/files'\n",
    "    headers = {\n",
    "        'Authorization': f\"Bearer {api_key}\",\n",
    "    }\n",
    "    data = aiohttp.FormData()\n",
    "    data.add_field('purpose', 'batch')\n",
    "    data.add_field('file', file_path.open('rb'), filename=file_path.name, content_type='application/jsonl')\n",
    "    async with session.post(url, headers=headers, data=data) as response:\n",
    "        response_json = await response.json()\n",
    "        if response.status != 200:\n",
    "            error_message = response_json.get(\"error\", {}).get(\"message\", \"Unknown error\")\n",
    "            raise Exception(f\"Error uploading {file_path.name}: {error_message}\")\n",
    "        file_id = response_json['id']\n",
    "        metadata = {\n",
    "            \"file_id\": file_id,\n",
    "            \"original_filename\": file_path.name,\n",
    "            \"status\": response_json['status'],\n",
    "            \"created_at\": response_json['created_at'],\n",
    "            \"upload_timestamp\": datetime.now().isoformat(),\n",
    "            \"bytes\": response_json['bytes'],\n",
    "            \"purpose\": response_json['purpose']\n",
    "        }\n",
    "        return metadata\n",
    "\n",
    "# --- Consumer Callbacks ---\n",
    "async def on_upload_message(message: aio_pika.IncomingMessage):\n",
    "    \"\"\"Process messages from the 'upload' queue: upload file and then forward for batch submission.\"\"\"\n",
    "    async with message.process():\n",
    "        try:\n",
    "            payload = json.loads(message.body)\n",
    "            file_path_str = payload.get(\"file_path\")\n",
    "            file_path = Path(file_path_str)\n",
    "            async with aiohttp.ClientSession() as session:\n",
    "                metadata = await upload_file(session, file_path)\n",
    "                logger.info(f\"Uploaded {file_path.name}: file_id {metadata['file_id']}\")\n",
    "                # Publish to the batch queue\n",
    "                batch_payload = {\n",
    "                    \"file_id\": metadata[\"file_id\"],\n",
    "                    \"original_filename\": metadata[\"original_filename\"]\n",
    "                }\n",
    "                channel = message.channel\n",
    "                exchange = await channel.get_exchange(EXCHANGE_NAME)\n",
    "                await exchange.publish(\n",
    "                    aio_pika.Message(body=json.dumps(batch_payload).encode()),\n",
    "                    routing_key=\"batch\"\n",
    "                )\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Upload processing failed: {e}\")\n",
    "            raise e  # Message will be rejected and eventually dead-lettered\n",
    "\n",
    "async def on_batch_message(message: aio_pika.IncomingMessage):\n",
    "    \"\"\"Process messages from the 'batch' queue: submit batch job.\"\"\"\n",
    "    async with message.process():\n",
    "        try:\n",
    "            payload = json.loads(message.body)\n",
    "            file_id = payload.get(\"file_id\")\n",
    "            async with aiohttp.ClientSession() as session:\n",
    "                batch_id = await submit_batch_job(session, file_id)\n",
    "                logger.info(f\"Batch submitted for file {file_id}: batch_id {batch_id}\")\n",
    "                # Publish to the completed queue\n",
    "                completed_payload = {\n",
    "                    \"file_id\": file_id,\n",
    "                    \"batch_id\": batch_id,\n",
    "                    \"timestamp\": datetime.now().isoformat()\n",
    "                }\n",
    "                channel = message.channel\n",
    "                exchange = await channel.get_exchange(EXCHANGE_NAME)\n",
    "                await exchange.publish(\n",
    "                    aio_pika.Message(body=json.dumps(completed_payload).encode()),\n",
    "                    routing_key=\"completed\"\n",
    "                )\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Batch processing failed: {e}\")\n",
    "            raise e\n",
    "\n",
    "# --- Main Function: Setup Exchanges, Queues, Producers, and Consumers ---\n",
    "async def main():\n",
    "    # Connect to RabbitMQ\n",
    "    connection = await aio_pika.connect_robust(RABBITMQ_URL)\n",
    "    async with connection:\n",
    "        channel = await connection.channel()\n",
    "\n",
    "        # Declare main exchange (direct) and dead-letter exchange (fanout)\n",
    "        exchange = await channel.declare_exchange(EXCHANGE_NAME, aio_pika.ExchangeType.DIRECT)\n",
    "        dlx = await channel.declare_exchange(DLX_NAME, aio_pika.ExchangeType.FANOUT)\n",
    "\n",
    "        # Declare queues with dead-letter exchange arguments\n",
    "        upload_queue = await channel.declare_queue(\n",
    "            UPLOAD_QUEUE,\n",
    "            durable=True,\n",
    "            arguments={\"x-dead-letter-exchange\": DLX_NAME}\n",
    "        )\n",
    "        batch_queue = await channel.declare_queue(\n",
    "            BATCH_QUEUE,\n",
    "            durable=True,\n",
    "            arguments={\"x-dead-letter-exchange\": DLX_NAME}\n",
    "        )\n",
    "        completed_queue = await channel.declare_queue(\n",
    "            COMPLETED_QUEUE,\n",
    "            durable=True,\n",
    "            arguments={\"x-dead-letter-exchange\": DLX_NAME}\n",
    "        )\n",
    "        # Declare a dead-letter queue for messages that fail repeatedly\n",
    "        dead_letter_queue = await channel.declare_queue(\"dead_letter_queue\", durable=True)\n",
    "        await dead_letter_queue.bind(dlx, routing_key=\"\")\n",
    "\n",
    "        # Bind queues to the exchange using routing keys\n",
    "        await upload_queue.bind(exchange, routing_key=\"upload\")\n",
    "        await batch_queue.bind(exchange, routing_key=\"batch\")\n",
    "        await completed_queue.bind(exchange, routing_key=\"completed\")\n",
    "\n",
    "        # Start consumers for the upload and batch queues\n",
    "        await upload_queue.consume(on_upload_message)\n",
    "        await batch_queue.consume(on_batch_message)\n",
    "\n",
    "        # --- Producer: Enqueue Upload Tasks ---\n",
    "        # Publish an upload task for every file matching \"batch_*.jsonl\" in output_dir\n",
    "        for file in sorted(output_dir.glob(\"batch_*.jsonl\")):\n",
    "            payload = {\"file_path\": str(file)}\n",
    "            await exchange.publish(\n",
    "                aio_pika.Message(body=json.dumps(payload).encode()),\n",
    "                routing_key=\"upload\"\n",
    "            )\n",
    "            logger.info(f\"Enqueued upload task for {file.name}\")\n",
    "\n",
    "        logger.info(\"Waiting for messages. To exit press CTRL+C\")\n",
    "        # Run indefinitely\n",
    "        await asyncio.Future()\n",
    "\n",
    "# Run the main function\n",
    "await main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No batch_id found in metadata file-14kUprdXHVfy4c9QFkGbrF_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-14wPTMV99qr2uNevJawPRd_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-1aDJ7SoQhDh12BAGzFNbgm_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-1ip9b9hkBn5hn6H8aFjRWy_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-1Kd8cmQieKgDQCnXmd5La5_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-1tHtrGc4YUDvVikckkYSJh_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-1trT6Y1JFP6y9tPP3ZvMjo_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-1xSYGqcq6bgi3nrGpi89Lw_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-2Bx2AnihwVWttqq4hnZk2T_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-2C7cEJYYYmT9q2DyNtQ8RM_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-2TB2XdH27JgaSA6qWwu8ih_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-2uV4Hyee78BvXhRgiSPsoh_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-2uXBAUtPgkwD7SWrrvnTA3_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-2VaFG4bWa7dQJG8bSsL2RK_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-2WrJCB9HmPXZuQESRVn2ms_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-2ZKu2KLsgrWvnA7Fbzm4DY_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-32RcAyXQoHTs7xXCP6LyFv_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-3AnqosnhE6seB3FPqeA9eo_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-3ckrz4rEg8hushubpStocy_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-3Dzj5qdhwk9Mn8WsHx19gN_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-3rAJ3gi8hAeNx3efTW1577_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-3W7SnFUAEGTvR5rPdSdyGa_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-3xpYBGYD9fp26XurVppPwA_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-4acYAejLi1J3ssBCkXXo4e_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-4Au9EvcvFQdzR9vztq7Mi9_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-4CugNy71pfCB2g3EEHrPKC_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-4mhUuHHHT7kzXfDRm88HAR_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-4qfAbVH3qxLDwE8cbDPWjj_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-4QQ9PgzS26PFTpyCixSwJp_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-4RAyqJjDWHFbcb1J5GFKt7_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-4uzSQsJdin7keVga5hf6vQ_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-4VCe4jN3AUqE5oZUkJsxdq_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-4xcT6za7C9feMi8J9JZmQ5_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-58HwBeSYMjggo7rfh9v4tw_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-5Ab2rFvcVshtBKAMeJTy6E_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-5DEz8cproJfb2fYGeNUjU9_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-5dj68kNAfWvJoK8Z3WzDpR_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-5iuuTjcRYMUnzNa3RfS9R3_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-5jG89CWKB9WM9XVXMDvG6a_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-5JuWQSNwTBsAcMVZ8VrNQf_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-5qgENiV9xVRhq4aS6WXjJg_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-5sTdvp8n1KKpeJSnsTVbPA_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-5sykfC9DRiFhXXXGFRzrnx_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-5T21QFmw3JgZrFKya2mtBB_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-5XmQPRNvx3d1qciXvJRsYg_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-5Y8yTLKzAfCGqwHrH4Epoy_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-63CYinvav9orV2uJTH3wan_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-65M9WtLWVnTK3hBWerm6mS_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-65yD8sYNixJpYh13jpGpNY_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-684uLGcsnunQ4ZK41r5tdL_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-6AHp78NgQ2sTjUecTq9kJV_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-6bjFyCtGF7ZhxEz9JdwTNa_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-6DDxV4HidwrMpgi9acYtU5_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-6dyWdTSRyxWB6NQeHsyaP6_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-6H53dph26ke3wKeURQtmVg_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-6H8tmHHnmRLGyKmTk8qyXr_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-6MDDgJWjLYD7w46Z29rHZ3_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-6r2fhQZHiezNPn62PvGaeo_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-6u2XFB1k2iXJVyvk9WJGKy_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-6x6Sqp94TMzTxGMjtjhzCa_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-75kX9V2x8mHdbAqPNndTC6_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-7Bnqie3SamzMUGa7mUnwPi_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-7bXjrBfr1cBuymWNUqXFrU_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-7C3UppM6AxaiqTKEZrAHoi_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-7CsXyTExN7vircjZk1rwss_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-7D1y4gg717coVwV2Z3duiA_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-7Dyek34uoLwJHRsSWzyTnH_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-7fTxXBkxr3eDZff4KUUnyC_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-7hpY5XHctFRsYyHxUJCDKP_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-7iKjrFwYPYhCTtPa6L6BaC_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-7L1jTBnYcNWJonNNRx84RV_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-7MayKbWgwGqMtYPw6WqNiZ_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-7NEsLyFo4T4nysgbx3LcTy_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-7ocMUNNwSPTRhkhoY5bTQr_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-7qtba2YHkXaiTecVmaNAzj_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-7RSibG6JJpJU9htKcBmwUY_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-7U4CRvGg83fmXNiE2Pem85_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-85g6E7poRZhCV86LE7x14j_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-8DCWH6DuJxhACgLkAJcPhc_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-8F23UnL9DwUiNDCoWaUK86_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-8MjU35ZDvKrPgFt4jpGCMo_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-8Rkb3fecN9WZXoTsiYQ8VM_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-8UsMRA7FFYJEyEjcMyMCoE_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-95LLS5fCj7nwSpeJ4DrbYz_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-979MhLKHgckCWxC3iXY6iR_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-9FBR97VybNANEuKe2FoAiz_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-9fRBne42tz7jyoD7mcagTs_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-9GjqzeEoFMjEHgxFNNeE16_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-9k3E8SjShwMkMAKi3GSxPp_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-9MDunjSs1FR1upvMi1tZFG_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-9p7wU9gERPtrEGZZbeT2vo_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-9VYwgNqxaKr2DwmwPsNKsN_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-9X1PTUfwZFjcwodjKzytam_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-9xmocj7ENLBdCnmRmdQYXq_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-9ysFDBfM3o6gx5pEfQAV1j_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-A1YAodK1ScA7ydxdoLLA3p_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-A3Cvy7qTe2Me36N99hA8ci_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-A3VjSV2GSmF7hr8YyBsJSP_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-A7Q98nbXPmUQwtKLxWnNkp_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-AaJb8iT98rhVSE4EU4MMgF_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-AEWmjnq9KLWvhwGVqYq3bN_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-AHEuiTz9D1dx2coSzVjMn4_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-AjqUvdJZpz8BEHpb5xoY6P_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-AKSC5LYQAAJTSjcjm74iwE_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-AoBxhsFNWocXP8GxwfuSMJ_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-AS2axTW9zwCpyhKmgHvnoh_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-AU2jtgGPEHP2TzKDn5jxJD_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-AuvQZE4JiJw4Y8QpLe69Rb_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-AwEHsQ5K4NB7sQv8XcdDkA_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-AyXMbW7CFfMwVcoov1Vg85_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-AZB64Kqr7PB5FMoPnYMmJH_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-BEJ8t8dK99YXX9WbiW9F3W_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-BeMr9mgFuVnQGxEoFin72b_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-BGC5UGqdgL2wtv4rH1qYQF_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-Bq7x1zNY4rGxioSbGQGzGT_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-BTwrinsHe2mCaYhqw6DJhe_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-BVaRUPETsRMgWkbhWrKbsp_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-BZJHJnTj4ogNmwdEudZsRv_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-C2AnETqP24GdU3TLwrDor2_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-C8YNxrmg8m5tc8UVCsngVd_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-C9sMDQTaAgpHqtZJSayFAu_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-CcotsEKm78GUQrvkHanqQS_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-CeBVv7MHoYvUfmw12aYW5h_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-CLgzS3wg9dFifH9XzHt6Md_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-CLsxNWrKtAmjBjqqmF2psW_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-CpZTCg8iFmSUYBsTpbQaFB_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-CRcnHHrHSDEXNnBamaHvKD_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-CRMeNTkRjqW7fDraZ2XegM_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-CseprJRHw4wWZSmQuwMPE8_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-Cwm1DxWGVUYoJP2ZNvnq6J_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-CXhz9Fgs8jw1t61Z3F2Ec9_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-D9xmSVLd4qVGFGeT99L5S5_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-DabXQgvF7v1FvtJEVwqokq_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-DEZngmfNGmgq9AAn7cHNjj_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-DHZs4nEfNLyQYUjLULhUBV_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-DMrXWFRZ6EjPg2kgYHGCAw_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-Drt7RTefcWAiSrVHRT4fZa_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-Ds7jxzUHW23EWpaT1E8hHn_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-DtTzbHNmzaWZ2ZGvUtFpKw_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-DWhenWbkhrnchvCLLSP6oj_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-DxLQA62mdnuRmaLBDfhU5v_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-Dz3Ay4mL8EsanWcntMcYzx_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-E3D4fjCb6JZvSzz1H4nWT2_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-E5jxCYt6FojGdTAVJGnC82_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-EGd4yUcCHpqVjnpe5QiVeZ_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-EHb6RFbDzXs4GNTK51CXTF_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-EHd6nnm26ugyNPtoiq9d6N_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-EKoPhUsmrtAeJ6njSdtn7E_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-Eq2UxK8Z68htdcHTeDZYHr_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-EuLoyQbxhWQoRTcLjrqXSn_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-EvMjuuswSZG15mgHQMN4oa_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-F8UrurMLpoYQZBHFDpzWsd_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-FDNWcnSBMygRJnWY3kaMf2_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-FgnsdYvTuaNsDTyQ6J1fTF_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-FJqYEaLjopZbHXCk5nFPXZ_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-FMA9Dyc4wZhrRtErNd2yak_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-FW9zC89qxuog5RA8srQVBM_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-FYbopazGu3rfrDisMMuYEW_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-FzB7wcodic3Y3Px4YMXcTn_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-G3JtRQ7f5NLAqAXk8kDozC_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-G4YpKynx1pSwFAhDoiuNYw_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-G5WsAs1sEjwwzEdr31W2S5_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-G78yJ3885NrRXgG2hULp6t_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-G7u8m6WDJmqgqCrbxfwqH5_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-GaLT5KzNLjDHjapkYJ6MN2_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-GCCLsyD1R4PrnzyFQ9p8CJ_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-GfUX64V3X98rsiVqd6rUJi_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-GmbKTrLdJrGag5pyCU1n2F_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-GpyLQMa9dWXMELwC77dtZD_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-Gu5ucTyjGrKDn1kDAZAtg5_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-Gyo5YkmThtuSvyZ4UPeaeV_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-GysmVEfD1ncgYoz1cKcsrx_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-Gz8FfxDyVGhfRF3rEJNwBH_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-H3beDZc5v21q4sTpUX9VpS_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-H4vNE9SfhwB2Y1BHmoTLeF_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-H64XuVXVL4hikyvsXFqKa8_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-H69gN4anqsRSogiTPVtUKn_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-H7cTqwnCQp3LUA7gXyq17d_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-H9iHzZPjJAh7TD2RCRHyo5_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-Ha8vnTUzj23T9hYMhuN65w_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-HAooNN29VrVtTpM8u9TY1E_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-HgSaLCFXd4ULuz2W5nks1b_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-Hke7gxjHNZHJwKmaYX934r_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-HqcSqnRndHdWWQCm7hijjr_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-HxUAdhTt7pwPEYKZHprNnT_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-J1NGuKaqZm3XvkkCmVoc3Q_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-J1yxvQjmwaMgCzwaaEWRL2_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-J9Y7pbJLGYANPeqkGbNByN_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-JBrxjA6M6BMcedc9523ye6_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-Ji7B1YjymApK1efCDaWrhr_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-Jk6zAWsG3JzMbZNpYNCPpp_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-JKyJXgLu8vJmRyE89chcoM_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-JpGPtGeuGKuP4zz5CdjHj1_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-JsXTdVbfX5PXeGXxRp4aZH_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-JuJA66AkRNkJ3fgpzrBNS1_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-JxMdiA7BDe5wwYBPpCv3Ja_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-JyS75w7HrpaRYZSoqL85RH_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-K5h7RCLnUijNvHsb4uKoxH_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-K5yuQmn3WiaauXdXmivHwY_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-K7Z572RtwYdRWVJSHmNJj4_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-K9PuGrMcN7hCTicE6p3PZu_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-KdEXLHMxYshqhA3oaEdWm1_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-KE77yswsZNQSRG9HcPUo9c_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-KfC6bfmKavG1YtcSojmymX_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-KJUnhuTchxPGRNgqgG7EYp_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-KoLFRoWZHbKbQ2SWc9ZnSd_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-KQTaF3GqCynzdPtagb69ig_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-Kr539uTeQvGAvb9Mf6imDs_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-KRtb8jzrcvZ16qntnGUdQF_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-KtPy8rRhL2NDeP6XceZeCx_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-KuXMx4L8f8aALiBDjFPXwE_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-KVypRose5g9nhH9n4dYCrs_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-KW3kwxKLVT3haAP1WqxQjU_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-KXTnzptN2VR6sZj53dfCRR_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-KZ5KGSfWwUo4rBJB8jmRqh_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-KzuWokbuCQk9qpbawyWJpE_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-L2JhQCJQ2vSowHs1jBCPwc_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-L9jhTVjaGviiLWKdc45Hcd_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-LcuHS1f7hq9bVvmr9RajPZ_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-LEdafnx2xqfk5gGv7w9e1n_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-LGQsXYEJPYibK2rhq4xAng_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-LGZYGHtDRbHtET9XcNvFLa_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-LHDME88WDSGBop64Gu1DjT_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-LjSkppnwd4Wt3jbefXCseW_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-LLrzVYJzyrjg8nrE8qgs87_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-LLXBk1eMaywZMhfyHr8HBe_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-LnvEr2yaNdzNLtJek8S3CN_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-LYaf76e7xEdxjjhv81SuE5_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-LZcc9NFFQZfERVapHPU9NU_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-M3fa4EaD9AwHFeVh8mmfjy_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-MBCWxo3LtJBTNq1CtfTJae_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-MBnV7Uhz5KUu8kre1YkWgU_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-MdU2xQ2kHPV4iKn8dwgkmh_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-MF5WGfmypbe4fjz5GVY4cB_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-MgfG7z1yA3r1ghV29iHTYb_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-MH7oQvB8xNBMQ8wyCJto1R_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-MHBf218Fdf3M3PiW37nWt3_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-Micr9BxyXAQ3u7FUMpCfEJ_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-MjgMCMARUv5AtvKsWzByFt_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-MK9FqTFcqUvJwgCMe5Ltas_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-MkoXgbpdNt7Y1NNk9JLkA4_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-MMuCwoZoRmChe2YTNqkjEE_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-Mocw4Rx3rMmQqo8eLT38jk_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-Mp1fFQLDaTPC7RYkRBGK7u_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-MpiBGHEWcnQNdfBM65YgpA_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-MqvSjNBbzK3jNdpuixJRYU_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-MSnH2YEiRUgtu4dcFskNoR_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-MvKPgaLiWZ33pKxJ7b8yS9_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-Mwop1x42kjWrjHtyhRjp68_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-N5z3yeX556jWMXSCt5GcMg_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-N6bozUnTVP3mL3yfk5gkXh_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-NCCBq5datGTPX6P46Cjnfg_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-NGFHZKXM6rm4FZLR2Ac2Pu_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-NKiEMVrrDT5Uki39HQLhzr_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-NmM4D3PNkkY8QsScdD49La_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-NNGcMewK1D49Kiq3G4QmFo_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-NnzoCdWPaipMRdYqz9bJJw_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-Ns3p2iRoCW1CYZFPe7xyHV_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-Nx1Fjxaj8jnVgtir4EhKtA_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-NzCRSL6fvbKRfJL7vssY18_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-P7svt85yEYtwubSMJmkmBp_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-PbzPkDg3qkBk4CqZ6o41Vt_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-PdrGnPZ3ARWQogJRmJhgJP_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-Ph7iqXm8CXEufJ5Sfdbu9s_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-PmB9CJRTu57qoK29jrj8PB_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-PmpphV9a9dBmw1W1MBm5oZ_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-PUkDWoML4iLk1zNBR7bQef_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-PvHRm98vaFiivdSTs9WHRn_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-PW9KsC1hgJqWwyX8PZfbS6_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-PWbtaCSwqb1xpQHKU4vv1K_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-Q4SBjZXCVWDwBb4VT6AVRt_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-Q8Nq6rsboy2VHDKtZygfkC_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-QbMumer3A7jTFQ8W9vEUVh_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-QbqELbvGvJTmXRyqF5wJPS_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-QbzUUJUW7pqFNeGKqxxwqF_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-QC8v4sheZTj4qXXgxhVeaL_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-QeRrPJNjspPsGAtYP5d9VE_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-QJNvBvZR23EFhB5hS6RwM4_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-QLmzQvqRYzNLAQ6HVdJLiU_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-QnKfHGfXfRXUXzxa1oMAtF_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-QQrHicmdgwqhgkeoYRsffc_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-QUnU4hjMSwWE7q1djB81nq_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-QVg2Nv7APicWXbRkQa9uPF_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-Qxte6oWrzRkXzSrUKEvwWn_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-QYpDwX2MDTqK3TMtNj3jfA_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-R2Fp4WVoEhsiuuG65QznRH_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-R4g3yqTkWod6vZdevibNNJ_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-R6exWfJXzdTEfB3mjyNKFJ_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-R7xPQcVFV7xzb4HoSkCH8h_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-RJKJJ4F5bDpX2RqwZBRiwT_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-RK8bL1JGPTYr7cqJZjW3e9_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-RQiY2WB828rCmR5KT61kfd_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-RwRtA6438ZjRjDJBFsTftv_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-RZihjevzPf8adrhNebueyr_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-RZVDyts6ncom1pA1nqsnH2_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-S1hYA2KMGHhoWikaWSnMUz_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-S43uPDgCxo8Bepebjj1qm4_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-S4CUcJJCg4uEHXYQck6rEv_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-S4RQn3bL9qBXcnSV2S7QuE_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-S5dhtR69WK4qekbgNRjcAJ_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-S5Xr6PJpZ9NWSLN7C6VmXH_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-SaMdPChzPHqN3dEGtpyrGC_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-ScSvpeD2BavXdH9ST7XRpY_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-SEA5Y4K6FXrJGSCkpPUiqc_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-SFciRamtTLT6zdmDF6tTNM_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-SftGzJCJVoo5aUY68QFAia_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-SgtX48aWUwNLwc7w4inWoK_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-SHdqRkrhyS6GJwmB8qQHRV_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-Siu24ZYxoEeUbQWPmvcDV1_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-SivBbJqLjexyfYDZNmYd5C_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-SKCgYKpkktcz4JcxU7EdWn_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-SLZXE3WM316CzRHJCxBiZh_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-SMw6RbLHEbJraVjSsYVpoB_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-SqaZStmRWsYriJXG74SBYR_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-SU6nsrFDngGmtJRrLRbfYS_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-SvwkPtYBAobnhBZAnSkZvn_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-T9Nb7LbdA3TqXtaXZxKsci_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-TAcLPgjuCCtA2p8U1F9iXA_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-TBsqNb3NZMfYUAtkehfLkk_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-Tehr6tFrus234o1ZpXy8NG_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-TiVUmogjN19sYZ3VF1aXGB_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-TmgW2v4LWMKG7JRW9XHoKH_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-ToMmR8K5a9fY5tVTS3zPZj_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-TRL3fpGkFfoukM2VVtA19u_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-Ts7cAVSgzbKJxmMAZphqbb_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-TsMGL6MpL7xY7suNZNvJ6o_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-TVjbyaCEq5WaruJZVppsdS_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-TZhFBpj5noYeX1VhTzHTtX_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-TZuAV8qpTEMxJN5q7rth45_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-U2gbEP5aAtDcrFCtaXECxe_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-U32TkcSjsWE3e6Uh4H8BSS_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-U654FTNtBZiUFjQyk5W9Nm_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-U9JFCt7Vm3gZF1tmEXN6Bx_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-UGqRLyi3Avg37iPYWp62Dr_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-UgShL1CURszK6X5WKu7Fsr_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-UiywJgDuWKxmb4dzxqWfZ1_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-UjjPDCiGmYXwhN13mtPfue_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-UoYZM23oKDFP1A6HZFQ9hb_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-UQyC33LNWtqFM3trZa6Khp_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-UTeYayEQe4ok22HqBz9iyS_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-UtHN4wuYyCjCRFt195rK2X_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-VBM3msArtJAwXo9PdKEsXK_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-VbwzyBBxuDewZK1HPm4QAE_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-VERWWGCH1o6XEu51HvFJfm_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-VFE88w1hJxy4BY12TzgsWL_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-Vjqx9zu2wpVAgdfTKC811y_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-VKqucm1gUU4Ju8x3jQNS7M_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-VU87Y5f4rgChAw19uL7fRd_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-VuELEh3UpTP9asU1pzZQVM_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-VX44sd2erfXQtt5DkYVU8g_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-W1uWUoWqrY3cAhc83kjjtE_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-W87eGWatpDRvkuJdX4nbtg_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-WAg92LCdsnf6gmvVDXtiHY_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-WCWFLNgfbmTg7noJWByrFq_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-WEEJYDEvhrtLym9PBA3r75_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-WEzWEgB5QvJnBYms1Q38bi_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-WJUZhRD8skueAVTW5MgBRQ_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-WKRU3PmYsn4PujBXvydtr5_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-WMYRo36w3EnT37EGrqUnaz_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-WnsHCzMiE4AnrPrtVFqsis_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-WNtv9698BdNgcjRaWPbinA_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-WP1qA4fjWzQeU6f3GQJezV_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-WYZkqGy3qGc6xL7RGz42x7_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-X32QEAH4mCDAxDaCNxYxrc_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-X3hKwkdjWRhf6xRTZSELPV_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-XHw9SjS8pjY1ML95XZsYzt_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-XJkUC4bVLiohLFbVC9z7vK_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-XKLDQGY5rrC6NDnxvTthjL_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-XSSGK7p2QCFWxBw8PqcDgf_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-XTqGn3MgjVEb6PeSnnNf6d_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-XwtvVKEFPrLBLpEtzsYF1G_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-Y3pTprcBRrf9cjSpgYzfLn_metadata.json. Skipping.\n",
      "No batch_id found in metadata file-YUrhnXS81A3AP4BABMojgu_metadata.json. Skipping.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import asyncio\n",
    "import aiohttp\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "import openai\n",
    "from tenacity import retry, stop_after_attempt, wait_exponential\n",
    "\n",
    "# Set your OpenAI API key\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "if not openai.api_key:\n",
    "    raise ValueError(\"Please set the OPENAI_API_KEY environment variable.\")\n",
    "\n",
    "# Define directories\n",
    "tracking_dir = Path('output_jsonl/tracking')\n",
    "results_dir = tracking_dir / \"results\"\n",
    "results_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Retry configuration: 3 attempts with exponential backoff\n",
    "@retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=60))\n",
    "async def fetch_batch_status(session, batch_id):\n",
    "    \"\"\"Fetch the status of a batch job.\"\"\"\n",
    "    url = f'https://api.openai.com/v1/batches/{batch_id}'\n",
    "    headers = {\n",
    "        'Authorization': f\"Bearer {openai.api_key}\",\n",
    "    }\n",
    "    async with session.get(url, headers=headers) as response:\n",
    "        if response.status == 200:\n",
    "            return await response.json()\n",
    "        else:\n",
    "            error_text = await response.text()\n",
    "            raise Exception(f\"Error fetching status for batch {batch_id}: {error_text}\")\n",
    "\n",
    "@retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=60))\n",
    "async def download_file(session, file_id, destination):\n",
    "    \"\"\"Download a file from OpenAI and save it to the destination.\"\"\"\n",
    "    url = f'https://api.openai.com/v1/files/{file_id}/content'\n",
    "    headers = {\n",
    "        'Authorization': f\"Bearer {openai.api_key}\",\n",
    "    }\n",
    "    async with session.get(url, headers=headers) as response:\n",
    "        if response.status == 200:\n",
    "            with open(destination, 'wb') as f:\n",
    "                f.write(await response.read())\n",
    "        else:\n",
    "            error_text = await response.text()\n",
    "            raise Exception(f\"Error downloading file {file_id}: {error_text}\")\n",
    "\n",
    "async def process_batch(session, metadata_path):\n",
    "    \"\"\"Process a single batch based on its metadata file.\"\"\"\n",
    "    with open(metadata_path, 'r') as f:\n",
    "        metadata = json.load(f)\n",
    "\n",
    "    batch_id = metadata.get('batch_id')\n",
    "    if not batch_id:\n",
    "        print(f\"No batch_id found in metadata {metadata_path.name}. Skipping.\")\n",
    "        return\n",
    "\n",
    "    # Check batch status\n",
    "    try:\n",
    "        print(f\"Checking status for batch {batch_id}...\")\n",
    "        batch_status = await fetch_batch_status(session, batch_id)\n",
    "        metadata['batch_status'] = batch_status['status']\n",
    "\n",
    "        # Save updated metadata\n",
    "        with open(metadata_path, 'w') as f:\n",
    "            json.dump(metadata, f, indent=2)\n",
    "\n",
    "        if batch_status['status'] == 'completed':\n",
    "            output_file_id = batch_status.get('output_file_id')\n",
    "            if output_file_id:\n",
    "                output_path = results_dir / f\"{batch_id}_results.jsonl\"\n",
    "                await download_file(session, output_file_id, output_path)\n",
    "                print(f\"Results for batch {batch_id} saved to {output_path}\")\n",
    "            else:\n",
    "                print(f\"Batch {batch_id} completed, but no output file found.\")\n",
    "        elif batch_status['status'] in ['failed', 'expired']:\n",
    "            print(f\"Batch {batch_id} failed or expired.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing batch {batch_id}: {e}\")\n",
    "\n",
    "async def main_check_batches():\n",
    "    \"\"\"Main function to check the status of all batch jobs.\"\"\"\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = []\n",
    "        for metadata_file in tracking_dir.glob(\"*_metadata.json\"):\n",
    "            tasks.append(process_batch(session, metadata_file))\n",
    "\n",
    "        await asyncio.gather(*tasks)\n",
    "\n",
    "# Run the batch checking function\n",
    "await main_check_batches()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
